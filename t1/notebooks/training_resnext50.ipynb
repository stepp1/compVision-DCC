{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T04:03:14.226759Z",
     "start_time": "2021-05-01T04:03:14.223628Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/step/Personal/UCH/2021-sem1/VisionComp/t1\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "if Path.cwd().parent.stem == 't1':\n",
    "    %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T04:03:16.264972Z",
     "start_time": "2021-05-01T04:03:14.227642Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "import train\n",
    "from train import *\n",
    "from dataset import ClothingSmall, parse_function, train_preprocess\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T04:03:16.267494Z",
     "start_time": "2021-05-01T04:03:16.265816Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "jsaavedr, 2020\n",
      "This allows you to train and test your model\n",
      "\n",
      "Before using this program, set the path where the folder \"covnet2\"  is stored.\n",
      "To use train.py, you will require to send the following parameters :\n",
      " * -config : A configuration file where a set of parameters for data construction and trainig is set.\n",
      " * -name: A section name in the configuration file.\n",
      " * -mode: [train, test] for training, testing, or showing  variables of the current model. By default this is set to 'train'\n",
      " * -save: Set true for saving the model\n",
      "\n",
      "\n",
      " Extension made by Victor Faraggi, 2021\n",
      "\n",
      " Added modularity. Now you can import the following functions:\n",
      "    - create_config(name, config_file=None, config_str=None)\n",
      "        -> return a ConfigurationFile from config_file path or config_str\n",
      "    - parse_config(config)\n",
      "        -> returns dict w/ tfr_files\n",
      "    - load_dataset(config, tfr_train_file, tfr_test_file)\n",
      "        -> returns a dict w/ train/test datasets, mean_image, input_shape and number_of_classes\n",
      "    - create_model(config, model_name, in_shape)\n",
      "        -> returns a tf model\n",
      "    - create_scheduler(config)\n",
      "        -> returns a scheduler\n",
      "    - create_opt(opt_name, config, scheduler=None)\n",
      "        -> returns an optimizer\n",
      "    - create_cbs(config)\n",
      "        -> returns a TensorBoardCallback and a CheckpointCallback\n",
      "    - run_model(mode, model, opt, datasets, config, train_cbs=None, test_cbs=None):\n",
      "        -> returns the training/test history\n",
      "    - save_model(model, config, fname)\n",
      "        -> saves the model\n",
      "\n",
      "    config argument is expected to be a ConfigurationFile\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(train.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNext-50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T04:03:16.270175Z",
     "start_time": "2021-05-01T04:03:16.268162Z"
    }
   },
   "outputs": [],
   "source": [
    "resnext50_config = \\\n",
    "\"\"\"[FASHION-RESNEXT50]\n",
    "# Training Related\n",
    "NUM_EPOCHS = 20\n",
    "NUM_CLASSES = 19\n",
    "BATCH_SIZE = 64\n",
    "SNAPSHOT_STEPS = 500\n",
    "VALIDATION_STEPS = 100\n",
    "LEARNING_RATE = 0.003\n",
    "DECAY_STEPS = 40000\n",
    "USE_L2 = True\n",
    "WEIGHT_DECAY = 1e-2\n",
    "\n",
    "SNAPSHOT_DIR = snapshots/snapshots-resnext/\n",
    "\n",
    "# Dataset Related\n",
    "DATA_DIR = data/clothing-small/\n",
    "SHUFFLE_SIZE = 10000\n",
    "CHANNELS = 3\n",
    "IMAGE_TYPE = IMAGE\n",
    "IMAGE_WIDTH = 224\n",
    "IMAGE_HEIGHT = 224\n",
    "\n",
    "#for tf_records to use multithreads\n",
    "USE_MULTITHREADS = True\n",
    "NUM_THREADS = 10\n",
    "\n",
    "#CKPFILE is used for fine tunning\n",
    "#CKPFILE =/home/step/Personal/UCH/2021-sem1/VisionComp/t1/chks\n",
    "\"\"\"\n",
    "\n",
    "with open(\"configs/t1_resnext50.config\", 'w') as conf:\n",
    "    conf.write(resnext50_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T04:03:17.056225Z",
     "start_time": "2021-05-01T04:03:16.270877Z"
    }
   },
   "outputs": [],
   "source": [
    "config = create_config(\"FASHION-RESNEXT50\", \"configs/t1_resnext50.config\")\n",
    "tfr_files = parse_config(config, mode='train')\n",
    "datasets = load_dataset(config, tfr_files['train'], tfr_files['test'], 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T04:03:17.333967Z",
     "start_time": "2021-05-01T04:03:17.056961Z"
    }
   },
   "outputs": [],
   "source": [
    "from dataset import ClothingSmall\n",
    "\n",
    "process_func = lambda img, label : train_preprocess(img, label, seed=[8, 8])\n",
    "\n",
    "csDataset = ClothingSmall(data_dir = config.get_data_dir())\n",
    "\n",
    "csDataset.prepare()\n",
    "\n",
    "csDataset.make_ds(parse_function, process_func)\n",
    "\n",
    "\n",
    "# datasets = {\n",
    "#     'train' : csDataset.train_ds,\n",
    "#     'test' : csDataset.test_ds\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T04:03:17.458641Z",
     "start_time": "2021-05-01T04:03:17.337489Z"
    }
   },
   "outputs": [],
   "source": [
    "tb_cb, chk_cb = create_cbs(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LRFinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T04:03:18.083816Z",
     "start_time": "2021-05-01T04:03:17.921110Z"
    },
    "code_folding": [
     6
    ]
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "from keras.callbacks import LambdaCallback\n",
    "import keras.backend as K\n",
    "\n",
    "\n",
    "class LRFinder:\n",
    "    \"\"\"\n",
    "    Plots the change of the loss function of a Keras model when the learning rate is exponentially increasing.\n",
    "    See for details:\n",
    "    https://towardsdatascience.com/estimating-optimal-learning-rate-for-a-deep-neural-network-ce32f2556ce0\n",
    "    \"\"\"\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.losses = []\n",
    "        self.lrs = []\n",
    "        self.best_loss = 1e9\n",
    "\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        # Log the learning rate\n",
    "        lr = K.get_value(self.model.optimizer.lr)\n",
    "        self.lrs.append(lr)\n",
    "\n",
    "        # Log the loss\n",
    "        loss = logs['loss']\n",
    "        self.losses.append(loss)\n",
    "\n",
    "        # Check whether the loss got too large or NaN\n",
    "        if math.isnan(loss) or loss > self.best_loss * 4:\n",
    "            self.model.stop_training = True\n",
    "            return\n",
    "\n",
    "        if loss < self.best_loss:\n",
    "            self.best_loss = loss\n",
    "\n",
    "        # Increase the learning rate for the next batch\n",
    "        lr *= self.lr_mult\n",
    "        K.set_value(self.model.optimizer.lr, lr)\n",
    "\n",
    "    def find(self, dataset, start_lr, end_lr, batch_size=64, epochs=1):\n",
    "        num_batches = epochs * 31977 / batch_size\n",
    "        self.lr_mult = (end_lr / start_lr) ** (1 / num_batches)\n",
    "\n",
    "        # Save weights into a file\n",
    "        self.model.save_weights('tmp.h5')\n",
    "\n",
    "        # Remember the original learning rate\n",
    "        original_lr = K.get_value(self.model.optimizer.lr)\n",
    "\n",
    "        # Set the initial learning rate\n",
    "        K.set_value(self.model.optimizer.lr, start_lr)\n",
    "\n",
    "        callback = LambdaCallback(on_batch_end=lambda batch, logs: self.on_batch_end(batch, logs))\n",
    "\n",
    "        self.model.fit(dataset, batch_size=batch_size, epochs=epochs, callbacks=[callback])\n",
    "\n",
    "        # Restore the weights to the state before model fitting\n",
    "        self.model.load_weights('tmp.h5')\n",
    "\n",
    "        # Restore the original learning rate\n",
    "        K.set_value(self.model.optimizer.lr, original_lr)\n",
    "\n",
    "    def plot_loss(self, n_skip_beginning=10, n_skip_end=5):\n",
    "        \"\"\"\n",
    "        Plots the loss.\n",
    "        Parameters:\n",
    "            n_skip_beginning - number of batches to skip on the left.\n",
    "            n_skip_end - number of batches to skip on the right.\n",
    "        \"\"\"\n",
    "        plt.ylabel(\"loss\")\n",
    "        plt.xlabel(\"learning rate (log scale)\")\n",
    "        plt.plot(self.lrs[n_skip_beginning:-n_skip_end], self.losses[n_skip_beginning:-n_skip_end])\n",
    "        plt.xscale('log')\n",
    "\n",
    "    def plot_loss_change(self, sma=1, n_skip_beginning=10, n_skip_end=5, y_lim=(-0.01, 0.01)):\n",
    "        \"\"\"\n",
    "        Plots rate of change of the loss function.\n",
    "        Parameters:\n",
    "            sma - number of batches for simple moving average to smooth out the curve.\n",
    "            n_skip_beginning - number of batches to skip on the left.\n",
    "            n_skip_end - number of batches to skip on the right.\n",
    "            y_lim - limits for the y axis.\n",
    "        \"\"\"\n",
    "        assert sma >= 1\n",
    "        derivatives = [0] * sma\n",
    "        for i in range(sma, len(self.lrs)):\n",
    "            derivative = (self.losses[i] - self.losses[i - sma]) / sma\n",
    "            derivatives.append(derivative)\n",
    "\n",
    "        plt.ylabel(\"rate of loss change\")\n",
    "        plt.xlabel(\"learning rate (log scale)\")\n",
    "        plt.plot(self.lrs[n_skip_beginning:-n_skip_end], derivatives[n_skip_beginning:-n_skip_end])\n",
    "        plt.xscale('log')\n",
    "        plt.ylim(y_lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T04:03:18.086668Z",
     "start_time": "2021-05-01T04:03:18.084683Z"
    }
   },
   "outputs": [],
   "source": [
    "def determineLearningRate(model, dataset, opt):    \n",
    "    batch_size = 128\n",
    "    epochs = 5\n",
    "    \n",
    "    model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "    lr_finder = LRFinder(model)\n",
    "    lr_finder.find(dataset, start_lr=1e-5, end_lr=1, batch_size=batch_size, epochs=epochs)\n",
    "    lr_finder.plot_loss(n_skip_beginning=20, n_skip_end=5)\n",
    "    plt.show()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T04:07:54.356279Z",
     "start_time": "2021-05-01T04:03:18.087500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is Resnext-50\n",
      "(224, 224, 3)\n",
      "Model: \"res_next_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "backbone (ResNetBackbone)    multiple                  23033024  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( multiple                  0         \n",
      "_________________________________________________________________\n",
      "classifier (Dense)           multiple                  38931     \n",
      "=================================================================\n",
      "Total params: 23,071,955\n",
      "Trainable params: 23,011,283\n",
      "Non-trainable params: 60,672\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 112s 202ms/step - loss: 5.3761 - accuracy: 0.0509\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 103s 195ms/step - loss: 7.0277 - accuracy: 0.0620\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 61s 112ms/step - loss: nan - accuracy: 0.0635\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<models.resnet.ResNext at 0x7f70d85285b0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model(config, 'resnext', csDataset.input_shape, use_mixed=True)\n",
    "determineLearningRate(model, datasets['train'], tf.keras.optimizers.SGD())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T04:13:33.739187Z",
     "start_time": "2021-05-01T04:07:54.359141Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is Resnext-50\n",
      "(224, 224, 3)\n",
      "Model: \"res_next_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "backbone (ResNetBackbone)    multiple                  23033024  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( multiple                  0         \n",
      "_________________________________________________________________\n",
      "classifier (Dense)           multiple                  38931     \n",
      "=================================================================\n",
      "Total params: 23,071,955\n",
      "Trainable params: 23,011,283\n",
      "Non-trainable params: 60,672\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 104s 189ms/step - loss: 8.0839 - accuracy: 0.0535\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 101s 190ms/step - loss: 8.2275 - accuracy: 0.0621\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 97s 185ms/step - loss: 8.1609 - accuracy: 0.0393\n",
      "Epoch 4/5\n",
      "160/500 [========>.....................] - ETA: 1:06 - loss: 8.2713 - accuracy: 0.0630"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/step/miniconda3/envs/vision-tf/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3437, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-13-e3b01b74cd9d>\", line 2, in <module>\n",
      "    determineLearningRate(model, datasets['train'], tf.keras.optimizers.Adam())\n",
      "  File \"<ipython-input-11-fdfd278c5e3a>\", line 9, in determineLearningRate\n",
      "    lr_finder.find(dataset, start_lr=1e-5, end_lr=1, batch_size=batch_size, epochs=epochs)\n",
      "  File \"<ipython-input-10-ed1c17934bfc>\", line 55, in find\n",
      "    self.model.fit(dataset, batch_size=batch_size, epochs=epochs, callbacks=[callback])\n",
      "  File \"/home/step/miniconda3/envs/vision-tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\", line 1183, in fit\n",
      "    tmp_logs = self.train_function(iterator)\n",
      "  File \"/home/step/miniconda3/envs/vision-tf/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 872, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"/home/step/miniconda3/envs/vision-tf/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\", line 900, in _call\n",
      "    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\n",
      "  File \"/home/step/miniconda3/envs/vision-tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 3023, in __call__\n",
      "    return graph_function._call_flat(\n",
      "  File \"/home/step/miniconda3/envs/vision-tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 1960, in _call_flat\n",
      "    return self._build_call_outputs(self._inference_function.call(\n",
      "  File \"/home/step/miniconda3/envs/vision-tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py\", line 591, in call\n",
      "    outputs = execute.execute(\n",
      "  File \"/home/step/miniconda3/envs/vision-tf/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\", line 59, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/step/miniconda3/envs/vision-tf/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/step/miniconda3/envs/vision-tf/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/step/miniconda3/envs/vision-tf/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/step/miniconda3/envs/vision-tf/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/step/miniconda3/envs/vision-tf/lib/python3.8/inspect.py\", line 1515, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/step/miniconda3/envs/vision-tf/lib/python3.8/inspect.py\", line 1473, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/step/miniconda3/envs/vision-tf/lib/python3.8/inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/step/miniconda3/envs/vision-tf/lib/python3.8/inspect.py\", line 751, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/home/step/miniconda3/envs/vision-tf/lib/python3.8/inspect.py\", line 720, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/home/step/miniconda3/envs/vision-tf/lib/python3.8/inspect.py\", line 705, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/home/step/miniconda3/envs/vision-tf/lib/python3.8/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-e3b01b74cd9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'resnext'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_mixed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdetermineLearningRate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-fdfd278c5e3a>\u001b[0m in \u001b[0;36mdetermineLearningRate\u001b[0;34m(model, dataset, opt)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mlr_finder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLRFinder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mlr_finder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mlr_finder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_skip_beginning\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_skip_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-ed1c17934bfc>\u001b[0m in \u001b[0;36mfind\u001b[0;34m(self, dataset, start_lr, end_lr, batch_size, epochs)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/vision-tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/vision-tf/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    871\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    873\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/vision-tf/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    899\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/vision-tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[0;32m~/miniconda3/envs/vision-tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n",
      "\u001b[0;32m~/miniconda3/envs/vision-tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/vision-tf/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/vision-tf/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2060\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2061\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2062\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/vision-tf/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2061\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2062\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2063\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2064\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/vision-tf/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/vision-tf/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
      "\u001b[0;32m~/miniconda3/envs/vision-tf/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/vision-tf/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/vision-tf/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "model = create_model(config, 'resnext', csDataset.input_shape, use_mixed=True)\n",
    "determineLearningRate(model, datasets['train'], tf.keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T04:13:33.742021Z",
     "start_time": "2021-05-01T04:03:14.237Z"
    }
   },
   "outputs": [],
   "source": [
    "model = create_model(config, 'resnext', csDataset.input_shape, use_mixed=True)\n",
    "determineLearningRate(model, datasets['train'], tf.keras.optimizers.Nadam())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T04:03:17.336738Z",
     "start_time": "2021-05-01T04:03:17.335122Z"
    }
   },
   "outputs": [],
   "source": [
    "cosine_sched = create_scheduler(config)\n",
    "opt = create_opt('nadam', config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T04:03:17.920398Z",
     "start_time": "2021-05-01T04:03:17.459436Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3070, compute capability 8.6\n",
      "Model is Resnext-50\n",
      "(224, 224, 3)\n",
      "Model: \"res_next\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "backbone (ResNetBackbone)    multiple                  23033024  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl multiple                  0         \n",
      "_________________________________________________________________\n",
      "classifier (Dense)           multiple                  38931     \n",
      "=================================================================\n",
      "Total params: 23,071,955\n",
      "Trainable params: 23,011,283\n",
      "Non-trainable params: 60,672\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(config, 'resnext', csDataset.input_shape, use_mixed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T04:13:33.742444Z",
     "start_time": "2021-05-01T04:03:14.238Z"
    }
   },
   "outputs": [],
   "source": [
    "datasets['train'] = datasets['train'].prefetch(1)\n",
    "datasets['test'] = datasets['test'].prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T04:13:33.742823Z",
     "start_time": "2021-05-01T04:03:14.240Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = run_model('train', model, opt, datasets, config, [chk_cb], [tb_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T04:13:33.743296Z",
     "start_time": "2021-05-01T04:03:14.242Z"
    }
   },
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T04:13:33.743798Z",
     "start_time": "2021-05-01T04:03:14.242Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T04:13:33.744243Z",
     "start_time": "2021-05-01T04:03:14.244Z"
    }
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
