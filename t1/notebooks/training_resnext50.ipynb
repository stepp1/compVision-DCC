{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T04:03:14.226759Z",
     "start_time": "2021-05-01T04:03:14.223628Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/step/Personal/UCH/2021-sem1/VisionComp/t1\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "if Path.cwd().parent.stem == 't1':\n",
    "    %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T04:03:16.264972Z",
     "start_time": "2021-05-01T04:03:14.227642Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "import train\n",
    "from train import *\n",
    "from dataset import ClothingSmall, parse_function, train_preprocess\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T04:03:16.267494Z",
     "start_time": "2021-05-01T04:03:16.265816Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "jsaavedr, 2020\n",
      "This allows you to train and test your model\n",
      "\n",
      "Before using this program, set the path where the folder \"covnet2\"  is stored.\n",
      "To use train.py, you will require to send the following parameters :\n",
      " * -config : A configuration file where a set of parameters for data construction and trainig is set.\n",
      " * -name: A section name in the configuration file.\n",
      " * -mode: [train, test] for training, testing, or showing  variables of the current model. By default this is set to 'train'\n",
      " * -save: Set true for saving the model\n",
      "\n",
      "\n",
      " Extension made by Victor Faraggi, 2021\n",
      "\n",
      " Added modularity. Now you can import the following functions:\n",
      "    - create_config(name, config_file=None, config_str=None)\n",
      "        -> return a ConfigurationFile from config_file path or config_str\n",
      "    - parse_config(config)\n",
      "        -> returns dict w/ tfr_files\n",
      "    - load_dataset(config, tfr_train_file, tfr_test_file)\n",
      "        -> returns a dict w/ train/test datasets, mean_image, input_shape and number_of_classes\n",
      "    - create_model(config, model_name, in_shape)\n",
      "        -> returns a tf model\n",
      "    - create_scheduler(config)\n",
      "        -> returns a scheduler\n",
      "    - create_opt(opt_name, config, scheduler=None)\n",
      "        -> returns an optimizer\n",
      "    - create_cbs(config)\n",
      "        -> returns a TensorBoardCallback and a CheckpointCallback\n",
      "    - run_model(mode, model, opt, datasets, config, train_cbs=None, test_cbs=None):\n",
      "        -> returns the training/test history\n",
      "    - save_model(model, config, fname)\n",
      "        -> saves the model\n",
      "\n",
      "    config argument is expected to be a ConfigurationFile\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(train.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNext-50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T04:03:16.270175Z",
     "start_time": "2021-05-01T04:03:16.268162Z"
    }
   },
   "outputs": [],
   "source": [
    "resnext50_config = \\\n",
    "\"\"\"[FASHION-RESNEXT50]\n",
    "# Training Related\n",
    "NUM_EPOCHS = 20\n",
    "NUM_CLASSES = 19\n",
    "BATCH_SIZE = 64\n",
    "SNAPSHOT_STEPS = 500\n",
    "VALIDATION_STEPS = 100\n",
    "LEARNING_RATE = 0.003\n",
    "DECAY_STEPS = 40000\n",
    "USE_L2 = True\n",
    "WEIGHT_DECAY = 1e-2\n",
    "\n",
    "SNAPSHOT_DIR = snapshots/snapshots-resnext/\n",
    "\n",
    "# Dataset Related\n",
    "DATA_DIR = data/clothing-small/\n",
    "SHUFFLE_SIZE = 10000\n",
    "CHANNELS = 3\n",
    "IMAGE_TYPE = IMAGE\n",
    "IMAGE_WIDTH = 224\n",
    "IMAGE_HEIGHT = 224\n",
    "\n",
    "#for tf_records to use multithreads\n",
    "USE_MULTITHREADS = True\n",
    "NUM_THREADS = 10\n",
    "\n",
    "#CKPFILE is used for fine tunning\n",
    "#CKPFILE =/home/step/Personal/UCH/2021-sem1/VisionComp/t1/chks\n",
    "\"\"\"\n",
    "\n",
    "with open(\"configs/t1_resnext50.config\", 'w') as conf:\n",
    "    conf.write(resnext50_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T04:03:17.056225Z",
     "start_time": "2021-05-01T04:03:16.270877Z"
    }
   },
   "outputs": [],
   "source": [
    "config = create_config(\"FASHION-RESNEXT50\", \"configs/t1_resnext50.config\")\n",
    "tfr_files = parse_config(config, mode='train')\n",
    "datasets = load_dataset(config, tfr_files['train'], tfr_files['test'], 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T04:03:17.333967Z",
     "start_time": "2021-05-01T04:03:17.056961Z"
    }
   },
   "outputs": [],
   "source": [
    "from dataset import ClothingSmall\n",
    "\n",
    "process_func = lambda img, label : train_preprocess(img, label, seed=[8, 8])\n",
    "\n",
    "csDataset = ClothingSmall(data_dir = config.get_data_dir())\n",
    "\n",
    "csDataset.prepare()\n",
    "\n",
    "csDataset.make_ds(parse_function, process_func)\n",
    "\n",
    "\n",
    "# datasets = {\n",
    "#     'train' : csDataset.train_ds,\n",
    "#     'test' : csDataset.test_ds\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T04:03:17.336738Z",
     "start_time": "2021-05-01T04:03:17.335122Z"
    }
   },
   "outputs": [],
   "source": [
    "cosine_sched = create_scheduler(config)\n",
    "opt = create_opt('nadam', config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T04:03:17.458641Z",
     "start_time": "2021-05-01T04:03:17.337489Z"
    }
   },
   "outputs": [],
   "source": [
    "tb_cb, chk_cb = create_cbs(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T04:03:17.920398Z",
     "start_time": "2021-05-01T04:03:17.459436Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3070, compute capability 8.6\n",
      "Model is Resnext-50\n",
      "(224, 224, 3)\n",
      "Model: \"res_next\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "backbone (ResNetBackbone)    multiple                  23033024  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl multiple                  0         \n",
      "_________________________________________________________________\n",
      "classifier (Dense)           multiple                  38931     \n",
      "=================================================================\n",
      "Total params: 23,071,955\n",
      "Trainable params: 23,011,283\n",
      "Non-trainable params: 60,672\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(config, 'resnext', csDataset.input_shape, use_mixed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T04:03:18.083816Z",
     "start_time": "2021-05-01T04:03:17.921110Z"
    },
    "code_folding": [
     6
    ]
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "from keras.callbacks import LambdaCallback\n",
    "import keras.backend as K\n",
    "\n",
    "\n",
    "class LRFinder:\n",
    "    \"\"\"\n",
    "    Plots the change of the loss function of a Keras model when the learning rate is exponentially increasing.\n",
    "    See for details:\n",
    "    https://towardsdatascience.com/estimating-optimal-learning-rate-for-a-deep-neural-network-ce32f2556ce0\n",
    "    \"\"\"\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.losses = []\n",
    "        self.lrs = []\n",
    "        self.best_loss = 1e9\n",
    "\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        # Log the learning rate\n",
    "        lr = K.get_value(self.model.optimizer.lr)\n",
    "        self.lrs.append(lr)\n",
    "\n",
    "        # Log the loss\n",
    "        loss = logs['loss']\n",
    "        self.losses.append(loss)\n",
    "\n",
    "        # Check whether the loss got too large or NaN\n",
    "        if math.isnan(loss) or loss > self.best_loss * 4:\n",
    "            self.model.stop_training = True\n",
    "            return\n",
    "\n",
    "        if loss < self.best_loss:\n",
    "            self.best_loss = loss\n",
    "\n",
    "        # Increase the learning rate for the next batch\n",
    "        lr *= self.lr_mult\n",
    "        K.set_value(self.model.optimizer.lr, lr)\n",
    "\n",
    "    def find(self, dataset, start_lr, end_lr, batch_size=64, epochs=1):\n",
    "        num_batches = epochs * 31977 / batch_size\n",
    "        self.lr_mult = (end_lr / start_lr) ** (1 / num_batches)\n",
    "\n",
    "        # Save weights into a file\n",
    "        self.model.save_weights('tmp.h5')\n",
    "\n",
    "        # Remember the original learning rate\n",
    "        original_lr = K.get_value(self.model.optimizer.lr)\n",
    "\n",
    "        # Set the initial learning rate\n",
    "        K.set_value(self.model.optimizer.lr, start_lr)\n",
    "\n",
    "        callback = LambdaCallback(on_batch_end=lambda batch, logs: self.on_batch_end(batch, logs))\n",
    "\n",
    "        self.model.fit(dataset, batch_size=batch_size, epochs=epochs, callbacks=[callback])\n",
    "\n",
    "        # Restore the weights to the state before model fitting\n",
    "        self.model.load_weights('tmp.h5')\n",
    "\n",
    "        # Restore the original learning rate\n",
    "        K.set_value(self.model.optimizer.lr, original_lr)\n",
    "\n",
    "    def plot_loss(self, n_skip_beginning=10, n_skip_end=5):\n",
    "        \"\"\"\n",
    "        Plots the loss.\n",
    "        Parameters:\n",
    "            n_skip_beginning - number of batches to skip on the left.\n",
    "            n_skip_end - number of batches to skip on the right.\n",
    "        \"\"\"\n",
    "        plt.ylabel(\"loss\")\n",
    "        plt.xlabel(\"learning rate (log scale)\")\n",
    "        plt.plot(self.lrs[n_skip_beginning:-n_skip_end], self.losses[n_skip_beginning:-n_skip_end])\n",
    "        plt.xscale('log')\n",
    "\n",
    "    def plot_loss_change(self, sma=1, n_skip_beginning=10, n_skip_end=5, y_lim=(-0.01, 0.01)):\n",
    "        \"\"\"\n",
    "        Plots rate of change of the loss function.\n",
    "        Parameters:\n",
    "            sma - number of batches for simple moving average to smooth out the curve.\n",
    "            n_skip_beginning - number of batches to skip on the left.\n",
    "            n_skip_end - number of batches to skip on the right.\n",
    "            y_lim - limits for the y axis.\n",
    "        \"\"\"\n",
    "        assert sma >= 1\n",
    "        derivatives = [0] * sma\n",
    "        for i in range(sma, len(self.lrs)):\n",
    "            derivative = (self.losses[i] - self.losses[i - sma]) / sma\n",
    "            derivatives.append(derivative)\n",
    "\n",
    "        plt.ylabel(\"rate of loss change\")\n",
    "        plt.xlabel(\"learning rate (log scale)\")\n",
    "        plt.plot(self.lrs[n_skip_beginning:-n_skip_end], derivatives[n_skip_beginning:-n_skip_end])\n",
    "        plt.xscale('log')\n",
    "        plt.ylim(y_lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T04:03:18.086668Z",
     "start_time": "2021-05-01T04:03:18.084683Z"
    }
   },
   "outputs": [],
   "source": [
    "def determineLearningRate(model, dataset, opt):    \n",
    "    batch_size = 128\n",
    "    epochs = 5\n",
    "    \n",
    "    model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "    lr_finder = LRFinder(model)\n",
    "    lr_finder.find(dataset, start_lr=1e-5, end_lr=1, batch_size=batch_size, epochs=epochs)\n",
    "    lr_finder.plot_loss(n_skip_beginning=20, n_skip_end=5)\n",
    "    plt.show()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-01T04:03:14.234Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is Resnext-50\n",
      "(224, 224, 3)\n",
      "Model: \"res_next_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "backbone (ResNetBackbone)    multiple                  23033024  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( multiple                  0         \n",
      "_________________________________________________________________\n",
      "classifier (Dense)           multiple                  38931     \n",
      "=================================================================\n",
      "Total params: 23,071,955\n",
      "Trainable params: 23,011,283\n",
      "Non-trainable params: 60,672\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "     86/Unknown - 30s 215ms/step - loss: 6.3463 - accuracy: 0.0475"
     ]
    }
   ],
   "source": [
    "model = create_model(config, 'resnext', csDataset.input_shape, use_mixed=True)\n",
    "determineLearningRate(model, datasets['train'], tf.keras.optimizers.SGD())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-01T04:03:14.235Z"
    }
   },
   "outputs": [],
   "source": [
    "model = create_model(config, 'resnext', csDataset.input_shape, use_mixed=True)\n",
    "determineLearningRate(model, datasets['train'], tf.keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-01T04:03:14.237Z"
    }
   },
   "outputs": [],
   "source": [
    "model = create_model(config, 'resnext', csDataset.input_shape, use_mixed=True)\n",
    "determineLearningRate(model, datasets['train'], tf.keras.optimizers.Nadam())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-01T04:03:14.238Z"
    }
   },
   "outputs": [],
   "source": [
    "datasets['train'] = datasets['train'].prefetch(1)\n",
    "datasets['test'] = datasets['test'].prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-01T04:03:14.240Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = run_model('train', model, opt, datasets, config, [chk_cb], [tb_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-01T04:03:14.242Z"
    }
   },
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-01T04:03:14.242Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-01T04:03:14.244Z"
    }
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
