{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b530442",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-25T05:53:29.104551Z",
     "start_time": "2021-05-25T05:53:29.093379Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/step/Personal/UCH/2021-sem1/VisionComp/t2\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "if Path.cwd().parent.stem == 't2':\n",
    "    %cd ..\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0961f312",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ee57f81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-25T05:53:30.922803Z",
     "start_time": "2021-05-25T05:53:29.105363Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 2174192935\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "pl.seed_everything(hash(\"setting a random seeds\") % 2**32 - 1)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# perform dataset simple check\n",
    "check = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a348532",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Define Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0260ba8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-25T05:53:31.358126Z",
     "start_time": "2021-05-25T05:53:30.923705Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split, DataLoader, Dataset\n",
    "from torchvision import transforms, datasets\n",
    "import skimage.morphology as morph\n",
    "\n",
    "class ErosionReplicate(object):\n",
    "    \"\"\"Applies Erosion to one channel and replicates the channel\"\"\"\n",
    "    def __call__(self, tensor):\n",
    "        one_channel = tensor[0, :, :]\n",
    "        one_channel = torch.from_numpy(morph.erosion(one_channel, morph.square(3)))    \n",
    "        tensor[0, :, :] = one_channel\n",
    "        tensor[1, :, :] = one_channel\n",
    "        tensor[2, :, :] = one_channel\n",
    "        return tensor\n",
    "        \n",
    "\n",
    "class SimpleDataset(datasets.ImageFolder):\n",
    "    def __init__(self, base_dir: str, kind: str):\n",
    "        tr = [\n",
    "            transforms.Resize([224,224]),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "        ]\n",
    "        \n",
    "        if kind == 'sketch':\n",
    "            self.base_dir = str(Path(base_dir) / 'png_w256')\n",
    "            tr += [ErosionReplicate()]\n",
    "        elif kind == 'photo': \n",
    "            self.base_dir = base_dir \n",
    "        \n",
    "        tr += [transforms.Normalize(mean=(0.5,0.5,0.5), std=(0.5,0.5,0.5))]\n",
    "        \n",
    "        self.transforms = transforms.Compose(tr)\n",
    "        \n",
    "        super(SimpleDataset, self).__init__(\n",
    "            self.base_dir, transform = self.transforms)\n",
    "        \n",
    "        self.n_classes = len(self.classes)\n",
    "        self.idx_to_class = {idx: label for label, idx in self.class_to_idx.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0ada7a",
   "metadata": {},
   "source": [
    "## Define DataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6038dda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-25T05:53:31.363630Z",
     "start_time": "2021-05-25T05:53:31.359026Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "        \n",
    "class SimpleDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_dir: str, kind: str, batch_size: int = 32, truncate: int = None,\n",
    "                train_split: int = 0.8, test_split: int = 0.5):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.kind = kind\n",
    "        self.truncate = truncate\n",
    "        self.train_split = train_split\n",
    "        self.test_split = test_split\n",
    "        \n",
    "    def setup(self, stage: str = None):\n",
    "        dataset = SimpleDataset(self.data_dir, kind = self.kind)\n",
    "        self.n_classes = dataset.n_classes\n",
    "        \n",
    "        if self.truncate is not None:\n",
    "            # Split the indices in a stratified way\n",
    "            indices = np.random.choice(len(dataset), size=(self.truncate,), replace=False)\n",
    "          \n",
    "            # Warp into Subsets\n",
    "            dataset = torch.utils.data.Subset(dataset, indices)\n",
    "            \n",
    "        self.dataset = dataset\n",
    "        \n",
    "        \n",
    "        train_set, test_set = torch.utils.data.random_split(dataset, \n",
    "            [int(self.train_split*len(dataset)), len(dataset) - int(self.train_split*len(dataset))])\n",
    "        \n",
    "        val_set, test_set = torch.utils.data.random_split(test_set, \n",
    "            [int(self.test_split*len(test_set)), len(test_set) - int(self.test_split*len(test_set))])        \n",
    "        \n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        if stage == 'fit' or stage is None:\n",
    "            self.train_set, self.val_set = train_set, val_set\n",
    "            \n",
    "        # Assign test dataset for use in dataloader(s)\n",
    "        if stage == 'test' or stage is None:\n",
    "            self.val_set, self.test_set = val_set, test_set\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_set, num_workers=6, batch_size=self.batch_size, pin_memory=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_set, num_workers=6, batch_size=self.batch_size, pin_memory=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_set, num_workers=6, batch_size=self.batch_size, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681fe056",
   "metadata": {},
   "source": [
    "### Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24fde053",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-25T05:53:31.375519Z",
     "start_time": "2021-05-25T05:53:31.364327Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if check:\n",
    "    import matplotlib.pyplot as plt\n",
    "    dm = SimpleDataModule('data/Sketch_EITZ/', kind='sketch')\n",
    "    dm.setup('fit')\n",
    "\n",
    "    x, y = dm.train_set[0]\n",
    "\n",
    "    plt.imshow(x.permute(2,1,0))\n",
    "\n",
    "    print('sketch eitz: \\t', y, dm.dataset.idx_to_class[y], dm.n_classes, len(dm.dataset))\n",
    "    \n",
    "    \n",
    "    dm = SimpleDataModule('data/Flickr25K/', kind='photo')\n",
    "    dm.setup('fit')\n",
    "\n",
    "    x, y = dm.train_set[0]\n",
    "\n",
    "    plt.imshow(x.permute(2,1,0))\n",
    "\n",
    "    print('flickr25k: \\t',y, dm.dataset.idx_to_class[y], dm.n_classes, len(dm.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02aa92c5",
   "metadata": {},
   "source": [
    "## Define Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16838034",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-25T05:53:31.387633Z",
     "start_time": "2021-05-25T05:53:31.376301Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "import torchmetrics\n",
    "\n",
    "class Classifier(pl.LightningModule):\n",
    "    def __init__(self, model: nn.Module, n_classes: int, params: int):\n",
    "        super().__init__()\n",
    "        \n",
    "        # add new fc layers            \n",
    "        model.fc = nn.Linear(model.fc.in_features, n_classes)        \n",
    "        self.net = model\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # hparams\n",
    "        self.hparams.update(params)\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        # two accs to have different states\n",
    "        self.acc_train = torchmetrics.Accuracy()\n",
    "        self.acc_val = torchmetrics.Accuracy()\n",
    "        self.test_val = torchmetrics.Accuracy()\n",
    "       \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "    def training_step(self, batch,  batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "\n",
    "        self.log('train/loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log('train/acc', self.acc_train(y_hat.softmax(dim=-1), y), \n",
    "                 on_step=False, on_epoch=True, prog_bar=False, logger=True)\n",
    "        return {'loss': loss}\n",
    "\n",
    "    def validation_step(self, batch, batch_ixd):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        \n",
    "        self.log('val_loss', loss, on_step=True, logger=False)\n",
    "        self.log('val/loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log('val/acc', self.acc_val(y_hat.softmax(dim=-1), y), \n",
    "                 on_step=False, on_epoch=True, prog_bar=False, logger=True)\n",
    "        return {'loss': loss}\n",
    "    \n",
    "    def test_step(self, batch, batch_ixd):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        \n",
    "        self.log('test/loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log('test/acc', self.test_val(y_hat.softmax(dim=-1), y), \n",
    "                 on_step=False, on_epoch=True, prog_bar=False, logger=True)\n",
    "        return {'loss': loss}\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        opt = [optim.SGD(\n",
    "            self.parameters(), \n",
    "            lr=self.hparams.lr,\n",
    "            momentum=0.9,\n",
    "            nesterov=True,\n",
    "            weight_decay=self.hparams.weight_decay\n",
    "        )]\n",
    "        sched = [optim.lr_scheduler.CyclicLR(opt[0], 10e-3, 20e-2, cycle_momentum=False)]\n",
    "        return opt, sched\n",
    "    \n",
    "    def optimizer_zero_grad(self, epoch, batch_idx, optimizer, optimizer_idx):\n",
    "        optimizer.zero_grad(set_to_none=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a9a2b6",
   "metadata": {},
   "source": [
    "## HParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1c72668",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-25T05:53:31.399254Z",
     "start_time": "2021-05-25T05:53:31.388326Z"
    }
   },
   "outputs": [],
   "source": [
    "PARAMS = {\n",
    "    'lr' : 10e-3,\n",
    "    'weight_decay': 0.03,\n",
    "    'max_epochs': 45,\n",
    "    'batch_size': 64,\n",
    "    'patience': 10,\n",
    "    'precision': 16,\n",
    "    'base_dir': Path('data/Sketch_EITZ/'),\n",
    "    'train_split': 0.8,\n",
    "    'test_split': 0.5,\n",
    "    'truncate':15000\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fd6355",
   "metadata": {},
   "source": [
    "## Loggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a505f45f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-25T05:53:31.409376Z",
     "start_time": "2021-05-25T05:53:31.400307Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NeptuneLogger will work in online mode\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.loggers.neptune import NeptuneLogger\n",
    "import os\n",
    "\n",
    "api_key = os.environ['NEPTUNE']\n",
    "\n",
    "logger = NeptuneLogger(\n",
    "    api_key=api_key,\n",
    "    project_name=\"victor.faraggi/vision-dcc\",\n",
    "    experiment_name='hw2-pretrain-eitz-0.3-sgd', # attention to git, this creates a directory\n",
    "    params=PARAMS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037c71cd",
   "metadata": {},
   "source": [
    "## Instantiate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a049d5bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-25T05:53:31.805634Z",
     "start_time": "2021-05-25T05:53:31.410405Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import models\n",
    "\n",
    "model = models.resnet34()\n",
    "\n",
    "dm = SimpleDataModule(\n",
    "    data_dir = PARAMS['base_dir'], \n",
    "    kind = 'sketch', \n",
    "    batch_size = PARAMS['batch_size'],\n",
    "    train_split = PARAMS['train_split'], \n",
    "    test_split = PARAMS['test_split'],\n",
    "    truncate = PARAMS['truncate']\n",
    ")\n",
    "\n",
    "dm.setup()\n",
    "\n",
    "clf = Classifier(model, dm.n_classes, PARAMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b70d4a5",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa16ce33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-25T05:53:31.813902Z",
     "start_time": "2021-05-25T05:53:31.806453Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pytorch_lightning.plugins import DDPPlugin\n",
    "from pytorch_lightning import callbacks as cb\n",
    "\n",
    "checkpoint_cb = cb.ModelCheckpoint(\n",
    "    monitor='val/loss',\n",
    "    dirpath='snapshots/resnet-eitz/',\n",
    "    filename='resnet-eitz-{epoch:02d}-{val_loss:.2f}',\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "early_stopping_cb = cb.EarlyStopping('val/loss', patience=PARAMS['patience'])\n",
    "\n",
    "# trainer = pl.Trainer(auto_lr_find=True)\n",
    "# lr_finder = trainer.tuner.lr_find(clf, datamodule=dm)\n",
    "# fig = lr_finder.plot(suggest=True)\n",
    "\n",
    "# trainer = pl.Trainer(\n",
    "#     logger=logger,\n",
    "#     callbacks=[checkpoint_cb, early_stopping_cb], \n",
    "#     gpus=-1,  \n",
    "#     max_epochs=PARAMS['max_epochs'],\n",
    "#     precision=PARAMS['precision'],\n",
    "#     plugins=DDPPlugin(find_unused_parameters=False),\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17517db6",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84125597",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-25T05:53:31.930714Z",
     "start_time": "2021-05-25T05:53:31.814809Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-7d07c94338ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "trainer.fit(clf, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d022f383",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-25T05:53:56.603334Z",
     "start_time": "2021-05-25T05:53:37.376047Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "Global seed set to 2174192935\n",
      "initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/victor.faraggi/vision-dcc/e/VIS-31\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "098bfcb0e03a4a8ba5c0ac5c32a762fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test/acc': 0.6499999761581421,\n",
      " 'test/loss': 1.2735302448272705,\n",
      " 'test/loss_epoch': 1.3579310178756714}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chk = 'snapshots/resnet-eitz/resnet-eitz-epoch=08-val_loss=1.04.ckpt'\n",
    "model = Classifier.load_from_checkpoint(chk)\n",
    "\n",
    "model.eval();\n",
    "trainer = pl.Trainer(\n",
    "    logger=logger,\n",
    "    gpus=-1,\n",
    "    plugins=DDPPlugin(find_unused_parameters=False)\n",
    ")\n",
    "\n",
    "trainer.test(model, datamodule=dm);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "886d67b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-25T05:54:06.065918Z",
     "start_time": "2021-05-25T05:53:56.604913Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "Global seed set to 2174192935\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95ea1c0b4d9a47fc8f55ab6ea53d290e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test/acc': 0.5973333120346069,\n",
      " 'test/loss': 1.5634576082229614,\n",
      " 'test/loss_epoch': 1.6621181964874268}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chk = 'snapshots/resnet-eitz/resnet-eitz-epoch=20-val/loss=0.98.ckpt'\n",
    "model = Classifier.load_from_checkpoint(chk)\n",
    "\n",
    "model.eval();\n",
    "trainer = pl.Trainer(\n",
    "    logger=logger,\n",
    "    gpus=-1,\n",
    "    plugins=DDPPlugin(find_unused_parameters=False)\n",
    ")\n",
    "\n",
    "trainer.test(model, datamodule=dm);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48fbfdd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-25T05:54:15.120128Z",
     "start_time": "2021-05-25T05:54:06.066914Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "Global seed set to 2174192935\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "033b4219cf49428093675b0c78b520ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test/acc': 0.7693333625793457,\n",
      " 'test/loss': 1.09409499168396,\n",
      " 'test/loss_epoch': 1.0121474266052246}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chk = 'snapshots/resnet-eitz/resnet-eitz-epoch=26-val_loss=0.68.ckpt'\n",
    "model = Classifier.load_from_checkpoint(chk)\n",
    "\n",
    "model.eval();\n",
    "trainer = pl.Trainer(\n",
    "    logger=logger,\n",
    "    gpus=-1,\n",
    "    plugins=DDPPlugin(find_unused_parameters=False)\n",
    ")\n",
    "trainer.test(model, datamodule=dm);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82d9d21f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-25T06:07:38.884381Z",
     "start_time": "2021-05-25T06:07:38.830141Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.net, 'snapshots/resnet-eitz/best.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae57d363",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-25T06:08:09.735868Z",
     "start_time": "2021-05-25T06:08:09.701566Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=250, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load('snapshots/resnet-eitz/best.ckpt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
