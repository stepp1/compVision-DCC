{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T09:13:24.168021Z",
     "start_time": "2021-06-17T09:13:22.360457Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9_FzH13EjseR",
    "outputId": "f97286eb-18ed-4f8f-bb65-50910599cf9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/step/Personal/UCH/2021-sem1/VisionComp/t3\n",
      "1.7.1 True\n",
      "gcc (GCC) 11.1.0\n",
      "Copyright (C) 2021 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# basic dependencies\n",
    "from pathlib import Path\n",
    "if Path.cwd().parent.stem == 't3':\n",
    "    %cd ..\n",
    "\n",
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "!gcc --version\n",
    "\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    %cd /content/drive/MyDrive/compVision-DCC/t3\n",
    "    \n",
    "    assert torch.__version__.startswith(\"1.8\")   \n",
    "    try: \n",
    "        import detectron2\n",
    "    except ImportError:\n",
    "        !pip install pyyaml>=5.1\n",
    "        !pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.8/index.html\n",
    "else:\n",
    "    %config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T09:13:24.553565Z",
     "start_time": "2021-06-17T09:13:24.169038Z"
    },
    "id": "ZyAvNCJMmvFF"
   },
   "outputs": [],
   "source": [
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T09:13:24.556694Z",
     "start_time": "2021-06-17T09:13:24.554386Z"
    },
    "id": "cuOurHUb2rVj"
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import cv2\n",
    "import numpy as np\n",
    "from IPython.display import clear_output, Image, display\n",
    "import PIL.Image\n",
    "\n",
    "def showarray(a, fmt='jpeg'):\n",
    "    a = np.uint8(np.clip(a, 0, 255))\n",
    "    f = io.BytesIO()\n",
    "    PIL.Image.fromarray(a).save(f, fmt)\n",
    "    display(Image(data=f.getvalue()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2bjrfb2LDeo"
   },
   "source": [
    "# Train on a custom dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tjbUIhSxUdm_"
   },
   "source": [
    "## Prepare the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tVJoOm6LVJwW"
   },
   "source": [
    "Register the dataset to detectron2, following the [detectron2 custom dataset tutorial](https://detectron2.readthedocs.io/tutorials/datasets.html).\n",
    "Here, the dataset is in its custom format, therefore we write a function to parse it and prepare it into detectron2's standard format. User should write such a function when using a dataset in custom format. See the tutorial for more details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T09:13:24.561531Z",
     "start_time": "2021-06-17T09:13:24.557607Z"
    },
    "id": "QdXnTQ3y4Nd1"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from detectron2.structures import BoxMode\n",
    "\n",
    "def get_checks_dict_train(base_dir: str):\n",
    "    base_dir = Path(base_dir)\n",
    "    img_dir = Path(base_dir) / \"images\"\n",
    "    annot_dir = Path(base_dir) / \"annotations\"\n",
    "\n",
    "    dataset_dicts = []\n",
    "    for idx, annot_f in enumerate(annot_dir.iterdir()):\n",
    "        # print(annot)\n",
    "        filename = annot_f.stem + '.png'\n",
    "        filename = img_dir / filename\n",
    "        height, width = cv2.imread(str(filename)).shape[:2]\n",
    "\n",
    "        with open(annot_f) as f:\n",
    "            img_annots = f.readlines()\n",
    "\n",
    "        record = {}\n",
    "        record[\"file_name\"] = str(filename)\n",
    "        record[\"image_id\"] = idx\n",
    "        record[\"height\"] = height\n",
    "        record[\"width\"] = width\n",
    "\n",
    "        objs = []\n",
    "        for annot in img_annots:\n",
    "            # example: 4: 83, 8, 43, 53\n",
    "            category_str, bbox_str = annot.split(':')\n",
    "        \n",
    "            bbox_str = bbox_str.split(',')\n",
    "            bbox = [int(p_str.strip()) for p_str in bbox_str]\n",
    "\n",
    "            obj = {\n",
    "                \"bbox\": bbox,\n",
    "                \"bbox_mode\": BoxMode.XYWH_ABS,\n",
    "                # \"segmentation\": [poly],\n",
    "                \"category_id\": int(category_str),\n",
    "            }\n",
    "            objs.append(obj)\n",
    "        record[\"annotations\"] = objs\n",
    "        dataset_dicts.append(record)\n",
    "    return dataset_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T09:13:24.564647Z",
     "start_time": "2021-06-17T09:13:24.562309Z"
    },
    "id": "6OVqWeP37gv0"
   },
   "outputs": [],
   "source": [
    "data_path = Path('data/orand-car-with-bbs')\n",
    "\n",
    "d = \"train\"\n",
    "DatasetCatalog.register(\"checks_\" + d, lambda d=d: get_checks_dict_train(data_path / d))\n",
    "MetadataCatalog.get(\"checks_\" + d).set(thing_classes=[str(i) for i in range(10)])\n",
    "\n",
    "\n",
    "checks_metadata = MetadataCatalog.get(\"checks_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T09:13:31.812695Z",
     "start_time": "2021-06-17T09:13:24.565938Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[06/17 05:13:27 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n",
      "\u001b[32m[06/17 05:13:29 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 6370, #annotations: 31492\n",
      "Saved 5733 entries in train.json and 637 in test.json\n"
     ]
    }
   ],
   "source": [
    "from detectron2.data.datasets.coco import register_coco_instances, convert_to_coco_dict\n",
    "import json\n",
    "\n",
    "checks_coco_dict = convert_to_coco_dict(\"checks_train\")\n",
    "\n",
    "with open('checks_coco.json', 'w') as fp:\n",
    "    json.dump(checks_coco_dict, fp)\n",
    "\n",
    "if not Path('cocosplit.py').exists():\n",
    "    !wget https://raw.githubusercontent.com/akarazniewicz/cocosplit/master/cocosplit.py\n",
    "!python cocosplit.py --having-annotations -s 0.9 checks_coco.json train.json test.json\n",
    "\n",
    "register_coco_instances(\"checks-train\", {}, \"train.json\", \"\")\n",
    "register_coco_instances(\"checks-test\", {}, \"test.json\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T09:13:34.688030Z",
     "start_time": "2021-06-17T09:13:31.813731Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "id": "N-ZXFO6w9Lh2",
    "outputId": "2cfa7f15-ce07-44fc-9517-061c5e85f7f5",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file_name': 'data/orand-car-with-bbs/train/images/0335_9010842_33296.png', 'image_id': 4527, 'height': 70, 'width': 920, 'annotations': [{'bbox': [97, 12, 35, 47], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 3}, {'bbox': [163, 11, 36, 50], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 3}, {'bbox': [251, 12, 33, 48], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 2}, {'bbox': [317, 12, 34, 46], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 9}, {'bbox': [382, 12, 37, 47], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 6}]}\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import detectron2.data.transforms as T\n",
    "\n",
    "dataset_dicts = get_checks_dict_train(data_path / \"train\")\n",
    "augs = T.AugmentationList([T.Resize((150, 500)), T.RandomContrast(1.5, 2.5)])\n",
    "\n",
    "for d in random.sample(dataset_dicts,1):\n",
    "    print(d)\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    input = T.AugInput(img)\n",
    "    transform = augs(input)  # type: T.Transform\n",
    "    image_transformed = input.image  # new image\n",
    "    \n",
    "    visualizer = Visualizer(image_transformed[:, :, ::-1], metadata=checks_metadata, scale=0.5)\n",
    "    out = visualizer.draw_dataset_dict(d)\n",
    "    showarray(out.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wlqXIXXhW8dA"
   },
   "source": [
    "## Train!\n",
    "\n",
    "Now, let's fine-tune a COCO-pretrained R50-FPN Mask R-CNN model on the balloon dataset. It takes ~6 minutes to train 300 iterations on Colab's K80 GPU, or ~2 minutes on a P100 GPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T09:13:34.690223Z",
     "start_time": "2021-06-17T09:13:34.688765Z"
    }
   },
   "outputs": [],
   "source": [
    "# !rm -r output_final/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T09:13:37.405581Z",
     "start_time": "2021-06-17T09:13:34.690976Z"
    },
    "nbdime-conflicts": {
     "local_diff": [
      {
       "key": "outputId",
       "op": "remove"
      }
     ],
     "remote_diff": [
      {
       "diff": [
        {
         "key": 0,
         "op": "addrange",
         "valuelist": [
          "33560646-3cf5-477e-a52a-a2d6e7ccd9f3"
         ]
        },
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "outputId",
       "op": "patch"
      }
     ]
    },
    "outputId": "cabb0034-7a3c-4beb-ad97-a201f62faa60",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[06/17 05:13:36 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): ResNet(\n",
      "    (stem): BasicStem(\n",
      "      (conv1): Conv2d(\n",
      "        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "      )\n",
      "    )\n",
      "    (res2): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res3): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (3): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res4): Sequential(\n",
      "      (0): TridentBottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): TridentConv(\n",
      "          in_channels=256, out_channels=256, kernel_size=(3, 3), num_branch=3, test_branch_idx=1, stride=(1, 1), paddings=[(1, 1), (2, 2), (3, 3)], dilations=[(1, 1), (2, 2), (3, 3)], groups=1, bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): TridentBottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): TridentConv(\n",
      "          in_channels=256, out_channels=256, kernel_size=(3, 3), num_branch=3, test_branch_idx=1, stride=(1, 1), paddings=[(1, 1), (2, 2), (3, 3)], dilations=[(1, 1), (2, 2), (3, 3)], groups=1, bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): TridentBottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): TridentConv(\n",
      "          in_channels=256, out_channels=256, kernel_size=(3, 3), num_branch=3, test_branch_idx=1, stride=(1, 1), paddings=[(1, 1), (2, 2), (3, 3)], dilations=[(1, 1), (2, 2), (3, 3)], groups=1, bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (3): TridentBottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): TridentConv(\n",
      "          in_channels=256, out_channels=256, kernel_size=(3, 3), num_branch=3, test_branch_idx=1, stride=(1, 1), paddings=[(1, 1), (2, 2), (3, 3)], dilations=[(1, 1), (2, 2), (3, 3)], groups=1, bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (4): TridentBottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): TridentConv(\n",
      "          in_channels=256, out_channels=256, kernel_size=(3, 3), num_branch=3, test_branch_idx=1, stride=(1, 1), paddings=[(1, 1), (2, 2), (3, 3)], dilations=[(1, 1), (2, 2), (3, 3)], groups=1, bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (5): TridentBottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): TridentConv(\n",
      "          in_channels=256, out_channels=256, kernel_size=(3, 3), num_branch=3, test_branch_idx=1, stride=(1, 1), paddings=[(1, 1), (2, 2), (3, 3)], dilations=[(1, 1), (2, 2), (3, 3)], groups=1, bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): TridentRPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): TridentRes5ROIHeads(\n",
      "    (pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (res5): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=2048, out_features=11, bias=True)\n",
      "      (bbox_pred): Linear(in_features=2048, out_features=40, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/17 05:13:36 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[06/17 05:13:36 d2.data.datasets.coco]: \u001b[0mLoaded 5733 images in COCO format from train.json\n",
      "\u001b[32m[06/17 05:13:36 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 5733 images left.\n",
      "\u001b[32m[06/17 05:13:36 d2.data.build]: \u001b[0mDistribution of instances among all 10 categories:\n",
      "\u001b[36m|  category  | #instances   | category   | #instances   | category   | #instances   |\n",
      "|:----------:|:-------------|:-----------|:-------------|:-----------|:-------------|\n",
      "|     0      | 8526         | 1          | 3168         | 2          | 2692         |\n",
      "|     3      | 2328         | 4          | 2172         | 5          | 2438         |\n",
      "|     6      | 1931         | 7          | 1704         | 8          | 1767         |\n",
      "|     9      | 1590         |            |              |            |              |\n",
      "|   total    | 28316        |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[06/17 05:13:36 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[06/17 05:13:36 d2.data.common]: \u001b[0mSerializing 5733 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/17 05:13:36 d2.data.common]: \u001b[0mSerialized dataset takes 2.77 MiB\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.python.keras.utils.generic_utils' has no attribute 'populate_dict_with_module_objects'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/ml-torch/lib/python3.8/site-packages/tensorboard/compat/__init__.py\u001b[0m in \u001b[0;36mtf\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnotf\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'notf' from 'tensorboard.compat' (/home/step/miniconda3/envs/ml-torch/lib/python3.8/site-packages/tensorboard/compat/__init__.py)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ff8c58a32a07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOUTPUT_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./output_final'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOUTPUT_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;31m# trainer = DefaultTrainer(cfg)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume_or_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Personal/UCH/2021-sem1/VisionComp/t3/utils/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cfg, val_loss, bs)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_val_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml-torch/lib/python3.8/site-packages/detectron2/engine/defaults.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cfg)\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mresume_or_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Personal/UCH/2021-sem1/VisionComp/t3/utils/trainer.py\u001b[0m in \u001b[0;36mbuild_hooks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mhooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         hooks.insert(-1, ValidationHook(\n\u001b[1;32m     60\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEVAL_PERIOD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml-torch/lib/python3.8/site-packages/detectron2/engine/defaults.py\u001b[0m in \u001b[0;36mbuild_hooks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0;31m# Here the default print/log frequency of each writer is used.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m             \u001b[0;31m# run writers in the end, so that evaluation metrics are written\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m             \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPeriodicWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_writers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperiod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml-torch/lib/python3.8/site-packages/detectron2/engine/defaults.py\u001b[0m in \u001b[0;36mbuild_writers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    420\u001b[0m             \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEventWriter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mEventWriter\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mobjects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \"\"\"\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdefault_writers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOUTPUT_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml-torch/lib/python3.8/site-packages/detectron2/engine/defaults.py\u001b[0m in \u001b[0;36mdefault_writers\u001b[0;34m(output_dir, max_iter)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mCommonMetricPrinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mJSONWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"metrics.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mTensorboardXWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m     ]\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml-torch/lib/python3.8/site-packages/detectron2/utils/events.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, log_dir, window_size, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorboard\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_writer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_write\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml-torch/lib/python3.8/site-packages/torch/utils/tensorboard/writer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, log_dir, comment, purge_step, max_queue, flush_secs, filename_suffix)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;31m# and recreated later as needed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_writer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_writers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_file_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;31m# Create default bins for histograms, see generate_testdata.py in tensorflow/tensorboard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml-torch/lib/python3.8/site-packages/torch/utils/tensorboard/writer.py\u001b[0m in \u001b[0;36m_get_file_writer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;34m\"\"\"Returns the default FileWriter instance. Recreates it if closed.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_writers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_writer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             self.file_writer = FileWriter(self.log_dir, self.max_queue,\n\u001b[0m\u001b[1;32m    252\u001b[0m                                           self.flush_secs, self.filename_suffix)\n\u001b[1;32m    253\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_writers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_logdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_writer\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml-torch/lib/python3.8/site-packages/torch/utils/tensorboard/writer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, log_dir, max_queue, flush_secs, filename_suffix)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# actually the ones passing in a PosixPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mlog_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         self.event_writer = EventFileWriter(\n\u001b[0m\u001b[1;32m     62\u001b[0m             log_dir, max_queue, flush_secs, filename_suffix)\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml-torch/lib/python3.8/site-packages/tensorboard/summary/writer/event_file_writer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, logdir, max_queue_size, flush_secs, filename_suffix)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \"\"\"\n\u001b[1;32m     75\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logdir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogdir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         self._file_name = (\n",
      "\u001b[0;32m~/miniconda3/envs/ml-torch/lib/python3.8/site-packages/tensorboard/lazy.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr_name)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mclass\u001b[0m \u001b[0mLazyModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModuleType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml-torch/lib/python3.8/site-packages/tensorboard/lazy.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(arg)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnothing\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mnothing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                     \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml-torch/lib/python3.8/site-packages/tensorboard/lazy.py\u001b[0m in \u001b[0;36mload_once\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mload_once\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloading\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0mload_once\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloading\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml-torch/lib/python3.8/site-packages/tensorboard/compat/__init__.py\u001b[0m in \u001b[0;36mtf\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml-torch/lib/python3.8/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml-torch/lib/python3.8/site-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfeature_column_lib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfeature_column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml-torch/lib/python3.8/site-packages/tensorflow/python/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# See b/110718070#comment18 for more details about this import.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml-torch/lib/python3.8/site-packages/tensorflow/python/keras/models.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmetrics_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml-torch/lib/python3.8/site-packages/tensorflow/python/keras/metrics.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbinary_crossentropy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml-torch/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minitializers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mregularizers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml-torch/lib/python3.8/site-packages/tensorflow/python/keras/initializers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;31m# from ALL_OBJECTS. We make no guarantees as to whether these objects will\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;31m# using their correct version.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m \u001b[0mpopulate_deserializable_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLOCAL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALL_OBJECTS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml-torch/lib/python3.8/site-packages/tensorflow/python/keras/initializers/__init__.py\u001b[0m in \u001b[0;36mpopulate_deserializable_objects\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mv2_objs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mbase_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitializers_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInitializer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     generic_utils.populate_dict_with_module_objects(\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0mv2_objs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0minitializers_v2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.python.keras.utils.generic_utils' has no attribute 'populate_dict_with_module_objects'"
     ]
    }
   ],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "from utils.trainer import MyTrainer\n",
    "from TridentNet.tridentnet import add_tridentnet_config\n",
    "\n",
    "\n",
    "cfg = get_cfg()\n",
    "add_tridentnet_config(cfg)\n",
    "\n",
    "cfg.merge_from_file('TridentNet/configs/tridentnet_fast_R_50_C4_3x.yaml')\n",
    "cfg.DATASETS.TRAIN = (\"checks-train\",)\n",
    "cfg.DATASETS.TEST = (\"checks-test\",)\n",
    "cfg.TEST.EVAL_PERIOD = 250\n",
    "\n",
    "\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.00005  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 1500    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
    "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
    "\n",
    "cfg.MODEL.WEIGHTS = \"models/best_mnist-trident.pth\"\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 32   # faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 10  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
    "cfg.MODEL.RPN.NMS_THRESH = 0.9\n",
    "cfg.MODEL.RPN.BBOX_REG_WEIGHTS = (2.0, 2.5, 1.0, 1.0)\n",
    "cfg.MODEL.RPN.LOSS_WEIGHT = 1.5 \n",
    "\n",
    "\n",
    "\n",
    "# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n",
    "cfg.OUTPUT_DIR = './output_final'\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = MyTrainer(cfg) \n",
    "# trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T09:13:37.407096Z",
     "start_time": "2021-06-17T09:13:22.374Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from detectron2.utils.visualizer import ColorMode\n",
    "from utils.trainer import InvertColors\n",
    "\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.6   # set a custom testing threshold\n",
    "cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST = 0.7     # set a custom testing threshold\n",
    "cfg.MODEL.RPN.NMS_THRESH = 0.3\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
    "\n",
    "predictor = DefaultPredictor(cfg)\n",
    "i = 0\n",
    "f = [(samp['file_name'], samp['annotations']) for samp in DatasetCatalog.get('checks-test')]\n",
    "\n",
    "augs = T.AugmentationList(\n",
    "    [\n",
    "        InvertColors(),\n",
    "        T.Resize((300,800)), \n",
    "        T.RandomContrast(1.5, 2.5),\n",
    "        T.PadTransform(100, 100, 100, 100),\n",
    "    ]\n",
    ")\n",
    "\n",
    "for file, categories in f:\n",
    "    \n",
    "    im = cv2.imread(file)\n",
    "    categories = [cats['category_id'] for cats in categories]\n",
    "    \n",
    "    input = T.AugInput(im)\n",
    "    transform = augs(input)  # type: T.Transform\n",
    "    im = input.image  # new image\n",
    "    \n",
    "    if i == 3:\n",
    "        outputs = predictor(im)\n",
    "        v = Visualizer(im[:, :, ::-1],\n",
    "                   metadata=checks_metadata, \n",
    "                   scale=1, \n",
    "                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n",
    "        )\n",
    "        out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "        showarray(out.get_image()[:, :, ::-1])\n",
    "        break\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T09:13:37.407607Z",
     "start_time": "2021-06-17T09:13:22.375Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "experiment_folder = 'output_final'\n",
    "\n",
    "def load_json_arr(json_path):\n",
    "    lines = []\n",
    "    with open(json_path, 'r') as f:\n",
    "        for line in f:\n",
    "            lines.append(json.loads(line))\n",
    "    return lines\n",
    "\n",
    "experiment_metrics = load_json_arr(experiment_folder + '/metrics.json')\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('Iteration')\n",
    "ax1.set_ylabel('Loss')\n",
    "\n",
    "ax1.plot(\n",
    "    [x['iteration'] for x in experiment_metrics if 'total_loss' in x],\n",
    "    [x['total_loss'] for x in experiment_metrics if 'total_loss' in x], color=\"red\", label=\"Total Loss\")\n",
    "\n",
    "ax1.plot(\n",
    "    [x['iteration'] for x in experiment_metrics if 'validation_loss' in x], \n",
    "    [x['validation_loss'] for x in experiment_metrics if 'validation_loss' in x], color=\"blue\", label=\"Val Loss\")\n",
    "    \n",
    "ax1.tick_params(axis='y')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T09:13:37.408042Z",
     "start_time": "2021-06-17T09:13:22.376Z"
    }
   },
   "outputs": [],
   "source": [
    "from detectron2.checkpoint import Checkpointer\n",
    "ckpt = Checkpointer(trainer.model, \"models\")\n",
    "ckpt.save(\"best_checks-trident\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Detectron2_checks_TridentNet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
