{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T09:01:23.312726Z",
     "start_time": "2021-06-15T09:01:21.663522Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9_FzH13EjseR",
    "outputId": "acacd821-c044-4cba-d0d6-54ef16404617"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/compVision-DCC/t3\n",
      "1.7.1 True\n",
      "gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
      "Copyright (C) 2017 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# basic dependencies\n",
    "from pathlib import Path\n",
    "if Path.cwd().parent.stem == 't3':\n",
    "    %cd ..\n",
    "\n",
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "!gcc --version\n",
    "\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    %cd /content/drive/MyDrive/compVision-DCC/t3\n",
    "    \n",
    "    assert torch.__version__.startswith(\"1.8\")   \n",
    "    try: \n",
    "        import detectron2\n",
    "    except ImportError:\n",
    "        !pip install pyyaml>=5.1\n",
    "        !pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.8/index.html\n",
    "else:\n",
    "    %config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T20:59:08.339786Z",
     "start_time": "2021-06-11T20:59:07.984469Z"
    },
    "id": "ZyAvNCJMmvFF",
    "nbdime-conflicts": {
     "local_diff": [
      {
       "diff": [
        {
         "diff": [
          {
           "key": 0,
           "op": "addrange",
           "valuelist": [
            "2021-06-15T17:52:32.765004Z"
           ]
          },
          {
           "key": 0,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": "end_time",
         "op": "patch"
        },
        {
         "diff": [
          {
           "key": 0,
           "op": "addrange",
           "valuelist": [
            "2021-06-15T17:52:32.761892Z"
           ]
          },
          {
           "key": 0,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": "start_time",
         "op": "patch"
        }
       ],
       "key": "ExecuteTime",
       "op": "patch"
      }
     ],
     "remote_diff": [
      {
       "key": "ExecuteTime",
       "op": "remove"
      }
     ]
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n"
     ]
    }
   ],
   "source": [
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "print(detectron2.__version__)\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T20:59:08.342871Z",
     "start_time": "2021-06-11T20:59:08.340756Z"
    },
    "id": "cuOurHUb2rVj",
    "nbdime-conflicts": {
     "local_diff": [
      {
       "diff": [
        {
         "diff": [
          {
           "key": 0,
           "op": "addrange",
           "valuelist": [
            "2021-06-15T09:01:23.707166Z"
           ]
          },
          {
           "key": 0,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": "end_time",
         "op": "patch"
        },
        {
         "diff": [
          {
           "key": 0,
           "op": "addrange",
           "valuelist": [
            "2021-06-15T09:01:23.705089Z"
           ]
          },
          {
           "key": 0,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": "start_time",
         "op": "patch"
        }
       ],
       "key": "ExecuteTime",
       "op": "patch"
      }
     ],
     "remote_diff": [
      {
       "key": "ExecuteTime",
       "op": "remove"
      }
     ]
    }
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import cv2\n",
    "import numpy as np\n",
    "from IPython.display import clear_output, Image, display\n",
    "import PIL.Image\n",
    "\n",
    "def showarray(a, fmt='jpeg'):\n",
    "    a = np.uint8(np.clip(a, 0, 255))\n",
    "    f = io.BytesIO()\n",
    "    PIL.Image.fromarray(a).save(f, fmt)\n",
    "    display(Image(data=f.getvalue()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2bjrfb2LDeo"
   },
   "source": [
    "# Train on a custom dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tjbUIhSxUdm_"
   },
   "source": [
    "## Prepare the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tVJoOm6LVJwW"
   },
   "source": [
    "Register the dataset to detectron2, following the [detectron2 custom dataset tutorial](https://detectron2.readthedocs.io/tutorials/datasets.html).\n",
    "Here, the dataset is in its custom format, therefore we write a function to parse it and prepare it into detectron2's standard format. User should write such a function when using a dataset in custom format. See the tutorial for more details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T20:59:08.347171Z",
     "start_time": "2021-06-11T20:59:08.343664Z"
    },
    "id": "QdXnTQ3y4Nd1",
    "nbdime-conflicts": {
     "local_diff": [
      {
       "diff": [
        {
         "diff": [
          {
           "diff": [
            {
             "key": 9,
             "op": "addrange",
             "valuelist": "5"
            },
            {
             "key": 9,
             "length": 1,
             "op": "removerange"
            },
            {
             "key": 11,
             "length": 1,
             "op": "removerange"
            },
            {
             "key": 13,
             "length": 2,
             "op": "removerange"
            },
            {
             "key": 18,
             "op": "addrange",
             "valuelist": "1:23"
            },
            {
             "key": 18,
             "length": 1,
             "op": "removerange"
            },
            {
             "key": 20,
             "length": 2,
             "op": "removerange"
            },
            {
             "key": 24,
             "op": "addrange",
             "valuelist": "688"
            },
            {
             "key": 24,
             "length": 1,
             "op": "removerange"
            }
           ],
           "key": 0,
           "op": "patch"
          }
         ],
         "key": "end_time",
         "op": "patch"
        },
        {
         "diff": [
          {
           "key": 0,
           "op": "addrange",
           "valuelist": [
            "2021-06-15T09:01:23.707941Z"
           ]
          },
          {
           "key": 0,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": "start_time",
         "op": "patch"
        }
       ],
       "key": "ExecuteTime",
       "op": "patch"
      }
     ],
     "remote_diff": [
      {
       "key": "ExecuteTime",
       "op": "remove"
      }
     ]
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from detectron2.structures import BoxMode\n",
    "\n",
    "def get_mnist_dict(base_dir: str):\n",
    "    base_dir = Path(base_dir)\n",
    "    img_dir = Path(base_dir) / \"images\"\n",
    "    annot_dir = Path(base_dir) / \"labels\"\n",
    "\n",
    "    dataset_dicts = []\n",
    "    for idx, annot_f in enumerate(annot_dir.iterdir()):\n",
    "        \n",
    "        # print(annot)\n",
    "        filename = annot_f.stem + '.png'\n",
    "        filename = img_dir / filename\n",
    "\n",
    "        if not filename.exists():\n",
    "            continue\n",
    "            \n",
    "        height, width = cv2.imread(str(filename)).shape[:2]\n",
    "\n",
    "        with open(annot_f) as f:\n",
    "            img_annots = f.readlines()[1:]\n",
    "\n",
    "        record = {}\n",
    "        record[\"file_name\"] = str(filename)\n",
    "        record[\"image_id\"] = idx\n",
    "        record[\"height\"] = height\n",
    "        record[\"width\"] = width\n",
    "\n",
    "        objs = []\n",
    "        for annot in img_annots:\n",
    "            # example: 4,83,8,43,53\n",
    "            \n",
    "            category_bbox_str = annot.split(',')\n",
    "            category_str, bbox_str = category_bbox_str[0], category_bbox_str[1:]\n",
    "            \n",
    "            bbox = [int(p_str.replace('\\n', '').strip()) for p_str in bbox_str]\n",
    "            obj = {\n",
    "                \"bbox\": bbox,\n",
    "                \"bbox_mode\": BoxMode.XYXY_ABS,\n",
    "                # \"segmentation\": [poly],\n",
    "                \"category_id\": int(category_str),\n",
    "            }\n",
    "            objs.append(obj)\n",
    "        record[\"annotations\"] = objs\n",
    "        dataset_dicts.append(record)\n",
    "    return dataset_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BP1Pc8GqaHqA",
    "outputId": "c614644a-c83c-4c3d-a759-fcfec52c5553"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\r\n"
     ]
    }
   ],
   "source": [
    "!ls 'data/mnist_detection_150_500/train/labels' -1 | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T20:59:08.673275Z",
     "start_time": "2021-06-11T20:59:08.670857Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "id": "6OVqWeP37gv0",
    "nbdime-conflicts": {
     "local_diff": [
      {
       "diff": [
        {
         "diff": [
          {
           "diff": [
            {
             "key": 9,
             "op": "addrange",
             "valuelist": "5"
            },
            {
             "key": 9,
             "length": 1,
             "op": "removerange"
            },
            {
             "key": 11,
             "length": 1,
             "op": "removerange"
            },
            {
             "key": 13,
             "length": 2,
             "op": "removerange"
            },
            {
             "key": 18,
             "op": "addrange",
             "valuelist": "1:23"
            },
            {
             "key": 18,
             "length": 1,
             "op": "removerange"
            },
            {
             "key": 20,
             "length": 1,
             "op": "removerange"
            },
            {
             "key": 23,
             "op": "addrange",
             "valuelist": "30"
            },
            {
             "key": 23,
             "length": 1,
             "op": "removerange"
            },
            {
             "key": 25,
             "op": "addrange",
             "valuelist": "7"
            },
            {
             "key": 25,
             "length": 1,
             "op": "removerange"
            }
           ],
           "key": 0,
           "op": "patch"
          }
         ],
         "key": "end_time",
         "op": "patch"
        },
        {
         "diff": [
          {
           "key": 0,
           "op": "addrange",
           "valuelist": [
            "2021-06-15T09:01:23.717632Z"
           ]
          },
          {
           "key": 0,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": "start_time",
         "op": "patch"
        }
       ],
       "key": "ExecuteTime",
       "op": "patch"
      }
     ],
     "remote_diff": [
      {
       "key": "ExecuteTime",
       "op": "remove"
      }
     ]
    },
    "outputId": "287c4402-2b91-4324-8280-519bc100a286"
   },
   "outputs": [],
   "source": [
    "data_path = Path('data/mnist_detection_150_500')\n",
    "\n",
    "for d in [\"train\", \"test\"]:\n",
    "    DatasetCatalog.register(\"mnist_\" + d, lambda d=d: get_mnist_dict(data_path / d))\n",
    "    MetadataCatalog.get(\"mnist_\" + d).set(thing_classes=[str(i) for i in range(10)])\n",
    "\n",
    "mnist_metadata_test = MetadataCatalog.get(\"mnist_test\")\n",
    "mnist_metadata = MetadataCatalog.get(\"mnist_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T09:01:24.940324Z",
     "start_time": "2021-06-15T09:01:23.733878Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[06/16 04:43:39 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n",
      "\u001b[32m[06/16 04:43:40 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 1000, #annotations: 5482\n"
     ]
    }
   ],
   "source": [
    "from detectron2.data.datasets.coco import register_coco_instances, convert_to_coco_dict\n",
    "import json\n",
    "\n",
    "mnist_coco_dict = convert_to_coco_dict(\"mnist_test\")\n",
    "\n",
    "with open('mnist_coco.json', 'w') as fp:\n",
    "    json.dump(mnist_coco_dict, fp)\n",
    "    \n",
    "register_coco_instances(\"mnist-test\", {}, \"mnist_coco.json\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T08:04:58.760507Z",
     "start_time": "2021-06-15T08:04:54.701160Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "deletable": false,
    "editable": false,
    "id": "N-ZXFO6w9Lh2",
    "outputId": "a7fc9ac4-740b-414b-c75c-76ac76a2d10a",
    "run_control": {
     "frozen": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file_name': 'data/mnist_detection_150_500/train/images/269.png', 'image_id': 5745, 'height': 150, 'width': 500, 'annotations': [{'bbox': [202, 37, 255, 99], 'bbox_mode': <BoxMode.XYXY_ABS: 0>, 'category_id': 7}, {'bbox': [428, 44, 482, 111], 'bbox_mode': <BoxMode.XYXY_ABS: 0>, 'category_id': 6}, {'bbox': [397, 27, 435, 75], 'bbox_mode': <BoxMode.XYXY_ABS: 0>, 'category_id': 6}, {'bbox': [483, 37, 495, 50], 'bbox_mode': <BoxMode.XYXY_ABS: 0>, 'category_id': 6}, {'bbox': [357, 24, 390, 65], 'bbox_mode': <BoxMode.XYXY_ABS: 0>, 'category_id': 8}, {'bbox': [88, 37, 111, 74], 'bbox_mode': <BoxMode.XYXY_ABS: 0>, 'category_id': 9}, {'bbox': [236, 10, 265, 44], 'bbox_mode': <BoxMode.XYXY_ABS: 0>, 'category_id': 7}]}\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import detectron2.data.transforms as T\n",
    "\n",
    "dataset_dicts = get_mnist_dict(data_path / \"train\")\n",
    "\n",
    "transform_list = [\n",
    "        T.Resize((300,800)),\n",
    "        T.PadTransform(10, 10, 10, 10),\n",
    "        T.RandomBrightness(0.8, 1.8),\n",
    "        T.RandomContrast(0.6, 1.3),\n",
    "        T.RandomSaturation(0.8, 1.4),\n",
    "        T.RandomRotation(angle=[90, 90]),\n",
    "        T.RandomLighting(0.7),\n",
    "        T.RandomFlip(prob=0.4, horizontal=False, vertical=True),\n",
    "    ]\n",
    "\n",
    "augs = T.AugmentationList(transform_list)\n",
    "\n",
    "for d in random.sample(dataset_dicts,1):\n",
    "    print(d)\n",
    "    boxes = np.array([annot['bbox'] for annot in d['annotations']])\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    input = T.AugInput(img, boxes=boxes.astype('float32'))\n",
    "    transform = augs(input)  # type: T.Transform\n",
    "    image_transformed = input.image  # new image\n",
    "    \n",
    "    visualizer = Visualizer(image_transformed[:, :, ::-1], metadata=mnist_metadata, scale=0.5)\n",
    "    out = visualizer.draw_dataset_dict(d)\n",
    "    showarray(out.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T20:59:13.110957Z",
     "start_time": "2021-06-11T20:59:09.235521Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 82
    },
    "id": "N-ZXFO6w9Lh2",
    "outputId": "3b97a73d-2073-4498-c390-449e80231bcc",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# dataset_dicts = get_mnist_dict(data_path / \"train\")\n",
    "# for d in random.sample(dataset_dicts,1):\n",
    "#     print(d)\n",
    "#     img = cv2.imread(d[\"file_name\"])\n",
    "#     visualizer = Visualizer(img[:, :, ::-1], metadata=mnist_metadata, scale=0.5)\n",
    "#     out = visualizer.draw_dataset_dict(d)\n",
    "#     showarray(out.get_image())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wlqXIXXhW8dA"
   },
   "source": [
    "## Train!\n",
    "\n",
    "Now, let's fine-tune a COCO-pretrained R50-FPN Mask R-CNN model on the balloon dataset. It takes ~6 minutes to train 300 iterations on Colab's K80 GPU, or ~2 minutes on a P100 GPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T09:01:25.060498Z",
     "start_time": "2021-06-15T09:01:24.941064Z"
    }
   },
   "outputs": [],
   "source": [
    "!rm -r output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-16T21:47:14.047355Z",
     "start_time": "2021-06-16T21:47:14.040202Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0002"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.0002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-16T21:47:16.731706Z",
     "start_time": "2021-06-16T21:47:16.729342Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T21:21:50.919155Z",
     "start_time": "2021-06-11T21:21:45.617478Z"
    },
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "x8joe8cTIuyt",
    "nbdime-conflicts": {
     "local_diff": [
      {
       "diff": [
        {
         "diff": [
          {
           "key": 0,
           "op": "addrange",
           "valuelist": [
            "2021-06-15T09:34:41.873342Z"
           ]
          },
          {
           "key": 0,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": "end_time",
         "op": "patch"
        },
        {
         "diff": [
          {
           "key": 0,
           "op": "addrange",
           "valuelist": [
            "2021-06-15T09:01:25.061655Z"
           ]
          },
          {
           "key": 0,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": "start_time",
         "op": "patch"
        }
       ],
       "key": "ExecuteTime",
       "op": "patch"
      },
      {
       "diff": [
        {
         "key": 0,
         "op": "addrange",
         "valuelist": [
          "3c535262-3b93-40f3-df58-f16ea12e5034"
         ]
        },
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "outputId",
       "op": "patch"
      }
     ],
     "remote_diff": [
      {
       "key": "ExecuteTime",
       "op": "remove"
      },
      {
       "diff": [
        {
         "key": 0,
         "op": "addrange",
         "valuelist": [
          "eb4c49b6-ca6b-4db6-d1ee-69c1f0362de9"
         ]
        },
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "outputId",
       "op": "patch"
      }
     ]
    },
    "outputId": "cabb0034-7a3c-4beb-ad97-a201f62faa60",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[06/16 04:44:02 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): ResNet(\n",
      "    (stem): BasicStem(\n",
      "      (conv1): Conv2d(\n",
      "        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "      )\n",
      "    )\n",
      "    (res2): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res3): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (3): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res4): Sequential(\n",
      "      (0): TridentBottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): TridentConv(\n",
      "          in_channels=256, out_channels=256, kernel_size=(3, 3), num_branch=3, test_branch_idx=1, stride=(1, 1), paddings=[(1, 1), (2, 2), (3, 3)], dilations=[(1, 1), (2, 2), (3, 3)], groups=1, bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): TridentBottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): TridentConv(\n",
      "          in_channels=256, out_channels=256, kernel_size=(3, 3), num_branch=3, test_branch_idx=1, stride=(1, 1), paddings=[(1, 1), (2, 2), (3, 3)], dilations=[(1, 1), (2, 2), (3, 3)], groups=1, bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): TridentBottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): TridentConv(\n",
      "          in_channels=256, out_channels=256, kernel_size=(3, 3), num_branch=3, test_branch_idx=1, stride=(1, 1), paddings=[(1, 1), (2, 2), (3, 3)], dilations=[(1, 1), (2, 2), (3, 3)], groups=1, bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (3): TridentBottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): TridentConv(\n",
      "          in_channels=256, out_channels=256, kernel_size=(3, 3), num_branch=3, test_branch_idx=1, stride=(1, 1), paddings=[(1, 1), (2, 2), (3, 3)], dilations=[(1, 1), (2, 2), (3, 3)], groups=1, bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (4): TridentBottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): TridentConv(\n",
      "          in_channels=256, out_channels=256, kernel_size=(3, 3), num_branch=3, test_branch_idx=1, stride=(1, 1), paddings=[(1, 1), (2, 2), (3, 3)], dilations=[(1, 1), (2, 2), (3, 3)], groups=1, bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (5): TridentBottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): TridentConv(\n",
      "          in_channels=256, out_channels=256, kernel_size=(3, 3), num_branch=3, test_branch_idx=1, stride=(1, 1), paddings=[(1, 1), (2, 2), (3, 3)], dilations=[(1, 1), (2, 2), (3, 3)], groups=1, bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): TridentRPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): TridentRes5ROIHeads(\n",
      "    (pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (res5): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=2048, out_features=11, bias=True)\n",
      "      (bbox_pred): Linear(in_features=2048, out_features=40, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[06/16 04:44:08 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 10000 images left.\n",
      "\u001b[32m[06/16 04:44:08 d2.data.build]: \u001b[0mDistribution of instances among all 10 categories:\n",
      "\u001b[36m|  category  | #instances   | category   | #instances   | category   | #instances   |\n",
      "|:----------:|:-------------|:-----------|:-------------|:-----------|:-------------|\n",
      "|     0      | 5404         | 1          | 6207         | 2          | 5480         |\n",
      "|     3      | 5498         | 4          | 5554         | 5          | 4919         |\n",
      "|     6      | 5435         | 7          | 5652         | 8          | 5450         |\n",
      "|     9      | 5524         |            |              |            |              |\n",
      "|   total    | 55123        |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[06/16 04:44:08 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[06/16 04:44:08 d2.data.common]: \u001b[0mSerializing 10000 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/16 04:44:09 d2.data.common]: \u001b[0mSerialized dataset takes 3.40 MiB\n",
      "\u001b[32m[06/16 04:44:09 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/16 04:44:09 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[06/16 04:44:09 d2.data.datasets.coco]: \u001b[0mLoaded 1000 images in COCO format from mnist_coco.json\n",
      "\u001b[32m[06/16 04:44:09 d2.data.build]: \u001b[0mDistribution of instances among all 10 categories:\n",
      "\u001b[36m|  category  | #instances   | category   | #instances   | category   | #instances   |\n",
      "|:----------:|:-------------|:-----------|:-------------|:-----------|:-------------|\n",
      "|     0      | 532          | 1          | 615          | 2          | 576          |\n",
      "|     3      | 560          | 4          | 522          | 5          | 483          |\n",
      "|     6      | 521          | 7          | 529          | 8          | 559          |\n",
      "|     9      | 585          |            |              |            |              |\n",
      "|   total    | 5482         |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[06/16 04:44:09 d2.data.common]: \u001b[0mSerializing 1000 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/16 04:44:09 d2.data.common]: \u001b[0mSerialized dataset takes 0.51 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 2048) in the checkpoint but (11, 2048) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (11,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 2048) in the checkpoint but (40, 2048) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (40,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[06/16 04:44:09 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:103: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370172916/work/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  num_fg = fg_inds.nonzero().numel()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[06/16 04:44:14 d2.utils.events]: \u001b[0m eta: 0:07:39  iter: 19  total_loss: 4.525  loss_cls: 2.501  loss_box_reg: 1.958  loss_rpn_cls: 0.01325  loss_rpn_loc: 0.01347  time: 0.1863  data_time: 0.0261  lr: 3.9962e-06  max_mem: 1587M\n",
      "\u001b[32m[06/16 04:44:17 d2.utils.events]: \u001b[0m eta: 0:07:41  iter: 39  total_loss: 4.503  loss_cls: 2.472  loss_box_reg: 1.99  loss_rpn_cls: 0.02236  loss_rpn_loc: 0.01484  time: 0.1870  data_time: 0.0049  lr: 7.9922e-06  max_mem: 1587M\n",
      "\u001b[32m[06/16 04:44:21 d2.utils.events]: \u001b[0m eta: 0:07:37  iter: 59  total_loss: 4.391  loss_cls: 2.407  loss_box_reg: 1.959  loss_rpn_cls: 0.01403  loss_rpn_loc: 0.01011  time: 0.1868  data_time: 0.0046  lr: 1.1988e-05  max_mem: 1587M\n",
      "\u001b[32m[06/16 04:44:25 d2.utils.events]: \u001b[0m eta: 0:07:30  iter: 79  total_loss: 4.343  loss_cls: 2.346  loss_box_reg: 1.952  loss_rpn_cls: 0.01017  loss_rpn_loc: 0.01067  time: 0.1865  data_time: 0.0045  lr: 1.5984e-05  max_mem: 1587M\n",
      "\u001b[32m[06/16 04:44:29 d2.utils.events]: \u001b[0m eta: 0:07:26  iter: 99  total_loss: 4.157  loss_cls: 2.203  loss_box_reg: 1.936  loss_rpn_cls: 0.01033  loss_rpn_loc: 0.007212  time: 0.1864  data_time: 0.0046  lr: 1.998e-05  max_mem: 1587M\n",
      "\u001b[32m[06/16 04:44:32 d2.utils.events]: \u001b[0m eta: 0:07:22  iter: 119  total_loss: 4.117  loss_cls: 2.113  loss_box_reg: 1.934  loss_rpn_cls: 0.01463  loss_rpn_loc: 0.01219  time: 0.1864  data_time: 0.0047  lr: 2.3976e-05  max_mem: 1587M\n",
      "\u001b[32m[06/16 04:44:36 d2.utils.events]: \u001b[0m eta: 0:07:19  iter: 139  total_loss: 3.944  loss_cls: 1.992  loss_box_reg: 1.914  loss_rpn_cls: 0.01043  loss_rpn_loc: 0.009565  time: 0.1865  data_time: 0.0048  lr: 2.7972e-05  max_mem: 1587M\n",
      "\u001b[32m[06/16 04:44:40 d2.utils.events]: \u001b[0m eta: 0:07:15  iter: 159  total_loss: 3.782  loss_cls: 1.81  loss_box_reg: 1.943  loss_rpn_cls: 0.009918  loss_rpn_loc: 0.009813  time: 0.1866  data_time: 0.0049  lr: 3.1968e-05  max_mem: 1587M\n",
      "\u001b[32m[06/16 04:44:44 d2.utils.events]: \u001b[0m eta: 0:07:12  iter: 179  total_loss: 3.718  loss_cls: 1.747  loss_box_reg: 1.949  loss_rpn_cls: 0.01128  loss_rpn_loc: 0.01026  time: 0.1867  data_time: 0.0047  lr: 3.5964e-05  max_mem: 1587M\n",
      "\u001b[32m[06/16 04:44:47 d2.utils.events]: \u001b[0m eta: 0:07:08  iter: 199  total_loss: 3.592  loss_cls: 1.645  loss_box_reg: 1.937  loss_rpn_cls: 0.01379  loss_rpn_loc: 0.01231  time: 0.1866  data_time: 0.0046  lr: 3.996e-05  max_mem: 1587M\n",
      "\u001b[32m[06/16 04:44:51 d2.utils.events]: \u001b[0m eta: 0:07:04  iter: 219  total_loss: 3.607  loss_cls: 1.619  loss_box_reg: 1.961  loss_rpn_cls: 0.01363  loss_rpn_loc: 0.01024  time: 0.1865  data_time: 0.0046  lr: 4.3956e-05  max_mem: 1587M\n",
      "\u001b[32m[06/16 04:44:55 d2.utils.events]: \u001b[0m eta: 0:07:01  iter: 239  total_loss: 3.471  loss_cls: 1.553  loss_box_reg: 1.93  loss_rpn_cls: 0.005559  loss_rpn_loc: 0.008867  time: 0.1866  data_time: 0.0046  lr: 4.7952e-05  max_mem: 1587M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/16 04:44:57 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[06/16 04:44:57 d2.data.datasets.coco]: \u001b[0mLoaded 1000 images in COCO format from mnist_coco.json\n",
      "\u001b[32m[06/16 04:44:57 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[06/16 04:44:57 d2.data.common]: \u001b[0mSerializing 1000 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/16 04:44:57 d2.data.common]: \u001b[0mSerialized dataset takes 0.51 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/16 04:44:57 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[06/16 04:44:57 d2.evaluation.evaluator]: \u001b[0mStart inference on 1000 images\n",
      "\u001b[32m[06/16 04:44:58 d2.evaluation.evaluator]: \u001b[0mInference done 11/1000. 0.0889 s / img. ETA=0:01:29\n",
      "\u001b[32m[06/16 04:45:03 d2.evaluation.evaluator]: \u001b[0mInference done 66/1000. 0.0909 s / img. ETA=0:01:26\n",
      "\u001b[32m[06/16 04:45:08 d2.evaluation.evaluator]: \u001b[0mInference done 121/1000. 0.0906 s / img. ETA=0:01:20\n",
      "\u001b[32m[06/16 04:45:13 d2.evaluation.evaluator]: \u001b[0mInference done 175/1000. 0.0909 s / img. ETA=0:01:16\n",
      "\u001b[32m[06/16 04:45:18 d2.evaluation.evaluator]: \u001b[0mInference done 230/1000. 0.0905 s / img. ETA=0:01:10\n",
      "\u001b[32m[06/16 04:45:23 d2.evaluation.evaluator]: \u001b[0mInference done 281/1000. 0.0909 s / img. ETA=0:01:07\n",
      "\u001b[32m[06/16 04:45:28 d2.evaluation.evaluator]: \u001b[0mInference done 334/1000. 0.0913 s / img. ETA=0:01:02\n",
      "\u001b[32m[06/16 04:45:33 d2.evaluation.evaluator]: \u001b[0mInference done 386/1000. 0.0918 s / img. ETA=0:00:57\n",
      "\u001b[32m[06/16 04:45:38 d2.evaluation.evaluator]: \u001b[0mInference done 440/1000. 0.0917 s / img. ETA=0:00:52\n",
      "\u001b[32m[06/16 04:45:43 d2.evaluation.evaluator]: \u001b[0mInference done 493/1000. 0.0920 s / img. ETA=0:00:47\n",
      "\u001b[32m[06/16 04:45:49 d2.evaluation.evaluator]: \u001b[0mInference done 548/1000. 0.0918 s / img. ETA=0:00:42\n",
      "\u001b[32m[06/16 04:45:54 d2.evaluation.evaluator]: \u001b[0mInference done 602/1000. 0.0918 s / img. ETA=0:00:37\n",
      "\u001b[32m[06/16 04:45:59 d2.evaluation.evaluator]: \u001b[0mInference done 657/1000. 0.0916 s / img. ETA=0:00:32\n",
      "\u001b[32m[06/16 04:46:04 d2.evaluation.evaluator]: \u001b[0mInference done 711/1000. 0.0917 s / img. ETA=0:00:27\n",
      "\u001b[32m[06/16 04:46:09 d2.evaluation.evaluator]: \u001b[0mInference done 763/1000. 0.0920 s / img. ETA=0:00:22\n",
      "\u001b[32m[06/16 04:46:14 d2.evaluation.evaluator]: \u001b[0mInference done 818/1000. 0.0919 s / img. ETA=0:00:17\n",
      "\u001b[32m[06/16 04:46:19 d2.evaluation.evaluator]: \u001b[0mInference done 867/1000. 0.0924 s / img. ETA=0:00:12\n",
      "\u001b[32m[06/16 04:46:24 d2.evaluation.evaluator]: \u001b[0mInference done 921/1000. 0.0924 s / img. ETA=0:00:07\n",
      "\u001b[32m[06/16 04:46:29 d2.evaluation.evaluator]: \u001b[0mInference done 976/1000. 0.0923 s / img. ETA=0:00:02\n",
      "\u001b[32m[06/16 04:46:31 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:33.622009 (0.094092 s / img per device, on 1 devices)\n",
      "\u001b[32m[06/16 04:46:31 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:31 (0.092280 s / img per device, on 1 devices)\n",
      "\u001b[32m[06/16 04:46:32 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[06/16 04:46:32 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n",
      "\u001b[32m[06/16 04:46:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.47s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[06/16 04:46:33 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[06/16 04:46:34 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 1.11 seconds.\n",
      "\u001b[32m[06/16 04:46:34 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[06/16 04:46:34 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.19 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.022\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.060\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.008\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.022\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.028\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.073\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.220\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.249\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.244\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.252\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "\u001b[32m[06/16 04:46:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 2.217 | 6.011  | 0.822  | 2.182 | 2.798 |  nan  |\n",
      "\u001b[32m[06/16 04:46:34 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[06/16 04:46:34 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP    | category   | AP     | category   | AP    |\n",
      "|:-----------|:------|:-----------|:-------|:-----------|:------|\n",
      "| 0          | 0.467 | 1          | 13.650 | 2          | 1.699 |\n",
      "| 3          | 0.595 | 4          | 0.887  | 5          | 0.719 |\n",
      "| 6          | 0.859 | 7          | 0.584  | 8          | 2.434 |\n",
      "| 9          | 0.278 |            |        |            |       |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[06/16 04:46:34 d2.engine.defaults]: \u001b[0mEvaluation results for mnist-test in csv format:\n",
      "\u001b[32m[06/16 04:46:34 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[06/16 04:46:34 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[06/16 04:46:34 d2.evaluation.testing]: \u001b[0mcopypaste: 2.2172,6.0112,0.8220,2.1824,2.7980,nan\n",
      "\u001b[32m[06/16 04:47:44 d2.utils.events]: \u001b[0m eta: 0:06:58  iter: 259  total_loss: 3.459  loss_cls: 1.547  loss_box_reg: 1.874  loss_rpn_cls: 0.01204  loss_rpn_loc: 0.01066  validation_loss: 3.62  time: 0.1868  data_time: 0.0049  lr: 5.1948e-05  max_mem: 2536M\n",
      "\u001b[32m[06/16 04:47:47 d2.utils.events]: \u001b[0m eta: 0:06:54  iter: 279  total_loss: 3.426  loss_cls: 1.472  loss_box_reg: 1.897  loss_rpn_cls: 0.008533  loss_rpn_loc: 0.009665  validation_loss: 3.62  time: 0.1870  data_time: 0.0049  lr: 5.5944e-05  max_mem: 2536M\n",
      "\u001b[32m[06/16 04:47:51 d2.utils.events]: \u001b[0m eta: 0:06:52  iter: 299  total_loss: 3.408  loss_cls: 1.47  loss_box_reg: 1.901  loss_rpn_cls: 0.01044  loss_rpn_loc: 0.009398  validation_loss: 3.62  time: 0.1871  data_time: 0.0048  lr: 5.994e-05  max_mem: 2536M\n",
      "\u001b[32m[06/16 04:47:55 d2.utils.events]: \u001b[0m eta: 0:06:49  iter: 319  total_loss: 3.299  loss_cls: 1.405  loss_box_reg: 1.855  loss_rpn_cls: 0.006235  loss_rpn_loc: 0.007913  validation_loss: 3.62  time: 0.1873  data_time: 0.0048  lr: 6.3936e-05  max_mem: 2536M\n",
      "\u001b[32m[06/16 04:47:59 d2.utils.events]: \u001b[0m eta: 0:06:45  iter: 339  total_loss: 3.369  loss_cls: 1.422  loss_box_reg: 1.91  loss_rpn_cls: 0.007448  loss_rpn_loc: 0.008853  validation_loss: 3.62  time: 0.1876  data_time: 0.0051  lr: 6.7932e-05  max_mem: 2536M\n",
      "\u001b[32m[06/16 04:48:03 d2.utils.events]: \u001b[0m eta: 0:06:42  iter: 359  total_loss: 3.291  loss_cls: 1.391  loss_box_reg: 1.879  loss_rpn_cls: 0.007161  loss_rpn_loc: 0.01057  validation_loss: 3.62  time: 0.1877  data_time: 0.0047  lr: 7.1928e-05  max_mem: 2536M\n",
      "\u001b[32m[06/16 04:48:07 d2.utils.events]: \u001b[0m eta: 0:06:38  iter: 379  total_loss: 3.271  loss_cls: 1.349  loss_box_reg: 1.882  loss_rpn_cls: 0.009814  loss_rpn_loc: 0.008047  validation_loss: 3.62  time: 0.1879  data_time: 0.0049  lr: 7.5924e-05  max_mem: 2536M\n",
      "\u001b[32m[06/16 04:48:10 d2.utils.events]: \u001b[0m eta: 0:06:35  iter: 399  total_loss: 3.259  loss_cls: 1.325  loss_box_reg: 1.888  loss_rpn_cls: 0.008493  loss_rpn_loc: 0.008933  validation_loss: 3.62  time: 0.1880  data_time: 0.0049  lr: 7.992e-05  max_mem: 2536M\n",
      "\u001b[32m[06/16 04:48:14 d2.utils.events]: \u001b[0m eta: 0:06:31  iter: 419  total_loss: 3.176  loss_cls: 1.285  loss_box_reg: 1.884  loss_rpn_cls: 0.006795  loss_rpn_loc: 0.008933  validation_loss: 3.62  time: 0.1881  data_time: 0.0050  lr: 8.3916e-05  max_mem: 2536M\n",
      "\u001b[32m[06/16 04:48:18 d2.utils.events]: \u001b[0m eta: 0:06:28  iter: 439  total_loss: 3.081  loss_cls: 1.229  loss_box_reg: 1.817  loss_rpn_cls: 0.006712  loss_rpn_loc: 0.009224  validation_loss: 3.62  time: 0.1882  data_time: 0.0050  lr: 8.7912e-05  max_mem: 2536M\n",
      "\u001b[32m[06/16 04:48:22 d2.utils.events]: \u001b[0m eta: 0:06:24  iter: 459  total_loss: 3.009  loss_cls: 1.188  loss_box_reg: 1.817  loss_rpn_cls: 0.005775  loss_rpn_loc: 0.009321  validation_loss: 3.62  time: 0.1883  data_time: 0.0048  lr: 9.1908e-05  max_mem: 2536M\n",
      "\u001b[32m[06/16 04:48:26 d2.utils.events]: \u001b[0m eta: 0:06:20  iter: 479  total_loss: 3.005  loss_cls: 1.178  loss_box_reg: 1.792  loss_rpn_cls: 0.005795  loss_rpn_loc: 0.008014  validation_loss: 3.62  time: 0.1884  data_time: 0.0050  lr: 9.5904e-05  max_mem: 2536M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/16 04:48:30 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[06/16 04:48:30 d2.data.datasets.coco]: \u001b[0mLoaded 1000 images in COCO format from mnist_coco.json\n",
      "\u001b[32m[06/16 04:48:30 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[06/16 04:48:30 d2.data.common]: \u001b[0mSerializing 1000 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/16 04:48:30 d2.data.common]: \u001b[0mSerialized dataset takes 0.51 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/16 04:48:30 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[06/16 04:48:30 d2.evaluation.evaluator]: \u001b[0mStart inference on 1000 images\n",
      "\u001b[32m[06/16 04:48:31 d2.evaluation.evaluator]: \u001b[0mInference done 11/1000. 0.0917 s / img. ETA=0:01:32\n",
      "\u001b[32m[06/16 04:48:36 d2.evaluation.evaluator]: \u001b[0mInference done 63/1000. 0.0951 s / img. ETA=0:01:30\n",
      "\u001b[32m[06/16 04:48:41 d2.evaluation.evaluator]: \u001b[0mInference done 115/1000. 0.0952 s / img. ETA=0:01:25\n",
      "\u001b[32m[06/16 04:48:46 d2.evaluation.evaluator]: \u001b[0mInference done 166/1000. 0.0959 s / img. ETA=0:01:21\n",
      "\u001b[32m[06/16 04:48:51 d2.evaluation.evaluator]: \u001b[0mInference done 218/1000. 0.0948 s / img. ETA=0:01:16\n",
      "\u001b[32m[06/16 04:48:56 d2.evaluation.evaluator]: \u001b[0mInference done 269/1000. 0.0953 s / img. ETA=0:01:11\n",
      "\u001b[32m[06/16 04:49:01 d2.evaluation.evaluator]: \u001b[0mInference done 320/1000. 0.0957 s / img. ETA=0:01:06\n",
      "\u001b[32m[06/16 04:49:06 d2.evaluation.evaluator]: \u001b[0mInference done 371/1000. 0.0959 s / img. ETA=0:01:01\n",
      "\u001b[32m[06/16 04:49:11 d2.evaluation.evaluator]: \u001b[0mInference done 422/1000. 0.0961 s / img. ETA=0:00:56\n",
      "\u001b[32m[06/16 04:49:16 d2.evaluation.evaluator]: \u001b[0mInference done 473/1000. 0.0962 s / img. ETA=0:00:51\n",
      "\u001b[32m[06/16 04:49:21 d2.evaluation.evaluator]: \u001b[0mInference done 524/1000. 0.0962 s / img. ETA=0:00:46\n",
      "\u001b[32m[06/16 04:49:26 d2.evaluation.evaluator]: \u001b[0mInference done 577/1000. 0.0960 s / img. ETA=0:00:41\n",
      "\u001b[32m[06/16 04:49:31 d2.evaluation.evaluator]: \u001b[0mInference done 630/1000. 0.0958 s / img. ETA=0:00:36\n",
      "\u001b[32m[06/16 04:49:36 d2.evaluation.evaluator]: \u001b[0mInference done 681/1000. 0.0959 s / img. ETA=0:00:31\n",
      "\u001b[32m[06/16 04:49:41 d2.evaluation.evaluator]: \u001b[0mInference done 732/1000. 0.0960 s / img. ETA=0:00:26\n",
      "\u001b[32m[06/16 04:49:47 d2.evaluation.evaluator]: \u001b[0mInference done 783/1000. 0.0961 s / img. ETA=0:00:21\n",
      "\u001b[32m[06/16 04:49:52 d2.evaluation.evaluator]: \u001b[0mInference done 832/1000. 0.0961 s / img. ETA=0:00:16\n",
      "\u001b[32m[06/16 04:49:57 d2.evaluation.evaluator]: \u001b[0mInference done 883/1000. 0.0962 s / img. ETA=0:00:11\n",
      "\u001b[32m[06/16 04:50:02 d2.evaluation.evaluator]: \u001b[0mInference done 936/1000. 0.0961 s / img. ETA=0:00:06\n",
      "\u001b[32m[06/16 04:50:07 d2.evaluation.evaluator]: \u001b[0mInference done 989/1000. 0.0959 s / img. ETA=0:00:01\n",
      "\u001b[32m[06/16 04:50:08 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:37.448153 (0.097938 s / img per device, on 1 devices)\n",
      "\u001b[32m[06/16 04:50:08 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:35 (0.095936 s / img per device, on 1 devices)\n",
      "\u001b[32m[06/16 04:50:08 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[06/16 04:50:08 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n",
      "\u001b[32m[06/16 04:50:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.49s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[06/16 04:50:09 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[06/16 04:50:10 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.98 seconds.\n",
      "\u001b[32m[06/16 04:50:10 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[06/16 04:50:10 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.20 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.115\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.267\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.062\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.132\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.111\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.193\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.402\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.419\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.414\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.425\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "\u001b[32m[06/16 04:50:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl  |\n",
      "|:------:|:------:|:------:|:------:|:------:|:-----:|\n",
      "| 11.459 | 26.699 | 6.182  | 13.206 | 11.060 |  nan  |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[06/16 04:50:10 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[06/16 04:50:10 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category   | AP     | category   | AP     |\n",
      "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| 0          | 24.215 | 1          | 24.637 | 2          | 10.778 |\n",
      "| 3          | 4.713  | 4          | 15.152 | 5          | 2.881  |\n",
      "| 6          | 9.048  | 7          | 10.323 | 8          | 7.140  |\n",
      "| 9          | 5.705  |            |        |            |        |\n",
      "\u001b[32m[06/16 04:50:11 d2.engine.defaults]: \u001b[0mEvaluation results for mnist-test in csv format:\n",
      "\u001b[32m[06/16 04:50:11 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[06/16 04:50:11 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[06/16 04:50:11 d2.evaluation.testing]: \u001b[0mcopypaste: 11.4593,26.6992,6.1824,13.2064,11.0600,nan\n",
      "\u001b[32m[06/16 04:51:19 d2.utils.events]: \u001b[0m eta: 0:06:17  iter: 499  total_loss: 2.927  loss_cls: 1.114  loss_box_reg: 1.758  loss_rpn_cls: 0.006438  loss_rpn_loc: 0.008518  validation_loss: 3.389  time: 0.1885  data_time: 0.0048  lr: 9.99e-05  max_mem: 2536M\n",
      "\u001b[32m[06/16 04:51:22 d2.utils.events]: \u001b[0m eta: 0:06:13  iter: 519  total_loss: 2.827  loss_cls: 1.087  loss_box_reg: 1.739  loss_rpn_cls: 0.008707  loss_rpn_loc: 0.01207  validation_loss: 3.389  time: 0.1886  data_time: 0.0050  lr: 0.0001039  max_mem: 2536M\n",
      "\u001b[32m[06/16 04:51:26 d2.utils.events]: \u001b[0m eta: 0:06:09  iter: 539  total_loss: 2.693  loss_cls: 1.063  loss_box_reg: 1.651  loss_rpn_cls: 0.006581  loss_rpn_loc: 0.009997  validation_loss: 3.389  time: 0.1887  data_time: 0.0049  lr: 0.00010789  max_mem: 2536M\n",
      "\u001b[32m[06/16 04:51:30 d2.utils.events]: \u001b[0m eta: 0:06:06  iter: 559  total_loss: 2.555  loss_cls: 0.9412  loss_box_reg: 1.596  loss_rpn_cls: 0.005472  loss_rpn_loc: 0.0094  validation_loss: 3.389  time: 0.1887  data_time: 0.0049  lr: 0.00011189  max_mem: 2536M\n",
      "\u001b[32m[06/16 04:51:34 d2.utils.events]: \u001b[0m eta: 0:06:02  iter: 579  total_loss: 2.354  loss_cls: 0.885  loss_box_reg: 1.432  loss_rpn_cls: 0.006723  loss_rpn_loc: 0.009475  validation_loss: 3.389  time: 0.1888  data_time: 0.0050  lr: 0.00011588  max_mem: 2536M\n",
      "\u001b[32m[06/16 04:51:38 d2.utils.events]: \u001b[0m eta: 0:05:58  iter: 599  total_loss: 2.191  loss_cls: 0.8338  loss_box_reg: 1.292  loss_rpn_cls: 0.00763  loss_rpn_loc: 0.0113  validation_loss: 3.389  time: 0.1889  data_time: 0.0050  lr: 0.00011988  max_mem: 2536M\n",
      "\u001b[32m[06/16 04:51:42 d2.utils.events]: \u001b[0m eta: 0:05:55  iter: 619  total_loss: 1.79  loss_cls: 0.665  loss_box_reg: 1.122  loss_rpn_cls: 0.005052  loss_rpn_loc: 0.007628  validation_loss: 3.389  time: 0.1891  data_time: 0.0050  lr: 0.00012388  max_mem: 2536M\n",
      "\u001b[32m[06/16 04:51:45 d2.utils.events]: \u001b[0m eta: 0:05:51  iter: 639  total_loss: 1.833  loss_cls: 0.6953  loss_box_reg: 1.144  loss_rpn_cls: 0.006674  loss_rpn_loc: 0.01138  validation_loss: 3.389  time: 0.1891  data_time: 0.0049  lr: 0.00012787  max_mem: 2536M\n"
     ]
    }
   ],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "from utils.trainer import MyTrainer\n",
    "from TridentNet.tridentnet import add_tridentnet_config\n",
    "\n",
    "cfg = get_cfg()\n",
    "add_tridentnet_config(cfg)\n",
    "\n",
    "cfg.merge_from_file('TridentNet/configs/tridentnet_fast_R_50_C4_3x.yaml')\n",
    "cfg.DATASETS.TRAIN = (\"mnist_train\",)\n",
    "cfg.DATASETS.TEST = (\"mnist-test\",)\n",
    "cfg.TEST.EVAL_PERIOD = 250\n",
    "cfg.DATALOADER.NUM_WORKERS = 9\n",
    "cfg.MODEL.WEIGHTS = 'https://dl.fbaipublicfiles.com/detectron2/TridentNet/tridentnet_fast_R_50_C4_1x/148572687/model_final_756cda.pkl'\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.00020  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 2500    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
    "\n",
    "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
    "\n",
    "# faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 32 \n",
    "# see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 10  \n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = MyTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T09:34:41.874452Z",
     "start_time": "2021-06-15T09:01:21.674Z"
    }
   },
   "outputs": [],
   "source": [
    "experiment_folder = 'output'\n",
    "\n",
    "def load_json_arr(json_path):\n",
    "    lines = []\n",
    "    with open(json_path, 'r') as f:\n",
    "        for line in f:\n",
    "            lines.append(json.loads(line))\n",
    "    return lines\n",
    "\n",
    "experiment_metrics = load_json_arr(experiment_folder + '/metrics.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T09:34:41.875271Z",
     "start_time": "2021-06-15T09:01:21.676Z"
    },
    "id": "oSQCDk-4Iuyt"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "experiment_folder = 'output'\n",
    "\n",
    "def load_json_arr(json_path):\n",
    "    lines = []\n",
    "    with open(json_path, 'r') as f:\n",
    "        for line in f:\n",
    "            lines.append(json.loads(line))\n",
    "    return lines\n",
    "\n",
    "experiment_metrics = load_json_arr(experiment_folder + '/metrics.json')\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('Iteration')\n",
    "ax1.set_ylabel('Loss')\n",
    "\n",
    "ax1.plot(\n",
    "    [x['iteration'] for x in experiment_metrics if 'total_loss' in x],\n",
    "    [x['total_loss'] for x in experiment_metrics if 'total_loss' in x], color=\"red\", label=\"Total Loss\")\n",
    "\n",
    "ax1.plot(\n",
    "    [x['iteration'] for x in experiment_metrics if 'validation_loss' in x], \n",
    "    [x['validation_loss'] for x in experiment_metrics if 'validation_loss' in x], color=\"blue\", label=\"Val Loss\")\n",
    "    \n",
    "ax1.tick_params(axis='y')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T09:34:41.875744Z",
     "start_time": "2021-06-15T09:01:21.677Z"
    }
   },
   "outputs": [],
   "source": [
    "from detectron2.checkpoint import Checkpointer\n",
    "ckpt = Checkpointer(trainer.model, \"models\")\n",
    "ckpt.save(\"best_mnist-trident\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T03:32:03.250253Z",
     "start_time": "2021-06-10T03:32:02.361251Z"
    },
    "id": "Ya5nEuMELeq8"
   },
   "outputs": [],
   "source": [
    "# Inference should use the config with parameters that are used in training\n",
    "# cfg now already contains everything we've set previously. We changed it a little bit for inference:\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set a custom testing threshold\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-05T08:10:12.897322Z",
     "start_time": "2021-06-05T08:10:12.102874Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "U5LhISJqWXgM",
    "outputId": "e6429bda-6253-4995-dbbd-a2d640e7770a",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from detectron2.utils.visualizer import ColorMode\n",
    "dataset_dicts = get_balloon_dicts(\"balloon/val\")\n",
    "for d in random.sample(dataset_dicts, 3):    \n",
    "    im = cv2.imread(d[\"file_name\"])\n",
    "    outputs = predictor(im)  # format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
    "    v = Visualizer(im[:, :, ::-1],\n",
    "                   metadata=balloon_metadata, \n",
    "                   scale=0.5, \n",
    "                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n",
    "    )\n",
    "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    showarray(out.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-05T08:10:18.012236Z",
     "start_time": "2021-06-05T08:10:12.898046Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h9tECBQCvMv3",
    "outputId": "45a5356c-a77d-4f49-e75b-7a4235f70724"
   },
   "outputs": [],
   "source": [
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "evaluator = COCOEvaluator(\"balloon_val\", (\"bbox\", \"segm\"), False, output_dir=\"./output/\")\n",
    "val_loader = build_detection_test_loader(cfg, \"balloon_val\")\n",
    "print(inference_on_dataset(trainer.model, val_loader, evaluator))\n",
    "# another equivalent way to evaluate the model is to use `trainer.test`"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Detectron2_mnist.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
