{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "140cb949",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-04T08:49:45.055143Z",
     "start_time": "2021-07-04T08:49:44.662087Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "11.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)\n",
    "\n",
    "# conda install -c omgarcia gcc-6 # install GCC version 6\n",
    "# conda install libgcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "189971ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-04T08:49:45.121434Z",
     "start_time": "2021-07-04T08:49:45.055927Z"
    }
   },
   "outputs": [],
   "source": [
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "from detectron2.config import get_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "749dd783",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-04T08:49:45.679048Z",
     "start_time": "2021-07-04T08:49:45.122363Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 33 entries in train.json and 12 in val.json\r\n"
     ]
    }
   ],
   "source": [
    "from detectron2.data.datasets.coco import register_coco_instances, convert_to_coco_dict\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "data_path = Path('data/SpermSegGS/')\n",
    "\n",
    "if not Path('cocosplit.py').exists():\n",
    "    !wget https://raw.githubusercontent.com/akarazniewicz/cocosplit/master/cocosplit.py\n",
    "!python cocosplit.py --having-annotations -s 0.75 coco_train.json train.json val.json\n",
    "\n",
    "register_coco_instances(\"sperm-train\", {}, \"train.json\", \"\")\n",
    "register_coco_instances(\"sperm-val\", {}, \"val.json\", \"\")\n",
    "register_coco_instances(\"sperm-test\", {}, \"coco_test.json\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77ba1ae8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-04T08:49:45.681493Z",
     "start_time": "2021-07-04T08:49:45.679827Z"
    }
   },
   "outputs": [],
   "source": [
    "# augmentation ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a75cd28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-04T08:49:45.683793Z",
     "start_time": "2021-07-04T08:49:45.682090Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8287ff83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-04T08:49:49.996022Z",
     "start_time": "2021-07-04T08:49:45.684379Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/04 04:49:47 d2.engine.defaults]: \u001b[0mModel:\n",
      "Detr(\n",
      "  (detr): DETRsegm(\n",
      "    (detr): DETR(\n",
      "      (transformer): Transformer(\n",
      "        (encoder): TransformerEncoder(\n",
      "          (layers): ModuleList(\n",
      "            (0): TransformerEncoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): TransformerEncoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (2): TransformerEncoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (3): TransformerEncoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (4): TransformerEncoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (5): TransformerEncoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (decoder): TransformerDecoder(\n",
      "          (layers): ModuleList(\n",
      "            (0): TransformerDecoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "              )\n",
      "              (multihead_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "              (dropout3): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): TransformerDecoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "              )\n",
      "              (multihead_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "              (dropout3): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (2): TransformerDecoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "              )\n",
      "              (multihead_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "              (dropout3): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (3): TransformerDecoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "              )\n",
      "              (multihead_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "              (dropout3): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (4): TransformerDecoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "              )\n",
      "              (multihead_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "              (dropout3): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (5): TransformerDecoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "              )\n",
      "              (multihead_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "              (dropout3): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (class_embed): Linear(in_features=256, out_features=81, bias=True)\n",
      "      (bbox_embed): MLP(\n",
      "        (layers): ModuleList(\n",
      "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (2): Linear(in_features=256, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (query_embed): Embedding(100, 256)\n",
      "      (input_proj): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (backbone): Joiner(\n",
      "        (0): MaskedBackbone(\n",
      "          (backbone): ResNet(\n",
      "            (stem): BasicStem(\n",
      "              (conv1): Conv2d(\n",
      "                3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "                (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "              )\n",
      "            )\n",
      "            (res2): Sequential(\n",
      "              (0): BottleneckBlock(\n",
      "                (shortcut): Conv2d(\n",
      "                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "                )\n",
      "                (conv1): Conv2d(\n",
      "                  64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "                )\n",
      "                (conv2): Conv2d(\n",
      "                  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "                )\n",
      "                (conv3): Conv2d(\n",
      "                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "                )\n",
      "              )\n",
      "              (1): BottleneckBlock(\n",
      "                (conv1): Conv2d(\n",
      "                  256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "                )\n",
      "                (conv2): Conv2d(\n",
      "                  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "                )\n",
      "                (conv3): Conv2d(\n",
      "                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "                )\n",
      "              )\n",
      "              (2): BottleneckBlock(\n",
      "                (conv1): Conv2d(\n",
      "                  256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "                )\n",
      "                (conv2): Conv2d(\n",
      "                  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "                  (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "                )\n",
      "                (conv3): Conv2d(\n",
      "                  64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (res3): Sequential(\n",
      "              (0): BottleneckBlock(\n",
      "                (shortcut): Conv2d(\n",
      "                  256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "                )\n",
      "                (conv1): Conv2d(\n",
      "                  256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "                )\n",
      "                (conv2): Conv2d(\n",
      "                  128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
      "                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "                )\n",
      "                (conv3): Conv2d(\n",
      "                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "                )\n",
      "              )\n",
      "              (1): BottleneckBlock(\n",
      "                (conv1): Conv2d(\n",
      "                  512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "                )\n",
      "                (conv2): Conv2d(\n",
      "                  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "                )\n",
      "                (conv3): Conv2d(\n",
      "                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "                )\n",
      "              )\n",
      "              (2): BottleneckBlock(\n",
      "                (conv1): Conv2d(\n",
      "                  512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "                )\n",
      "                (conv2): Conv2d(\n",
      "                  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "                )\n",
      "                (conv3): Conv2d(\n",
      "                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "                )\n",
      "              )\n",
      "              (3): BottleneckBlock(\n",
      "                (conv1): Conv2d(\n",
      "                  512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "                )\n",
      "                (conv2): Conv2d(\n",
      "                  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "                  (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "                )\n",
      "                (conv3): Conv2d(\n",
      "                  128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (res4): Sequential(\n",
      "              (0): BottleneckBlock(\n",
      "                (shortcut): Conv2d(\n",
      "                  512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "                )\n",
      "                (conv1): Conv2d(\n",
      "                  512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "                )\n",
      "                (conv2): Conv2d(\n",
      "                  256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
      "                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "                )\n",
      "                (conv3): Conv2d(\n",
      "                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "                )\n",
      "              )\n",
      "              (1): BottleneckBlock(\n",
      "                (conv1): Conv2d(\n",
      "                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "                )\n",
      "                (conv2): Conv2d(\n",
      "                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "                )\n",
      "                (conv3): Conv2d(\n",
      "                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "                )\n",
      "              )\n",
      "              (2): BottleneckBlock(\n",
      "                (conv1): Conv2d(\n",
      "                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "                )\n",
      "                (conv2): Conv2d(\n",
      "                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "                )\n",
      "                (conv3): Conv2d(\n",
      "                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "                )\n",
      "              )\n",
      "              (3): BottleneckBlock(\n",
      "                (conv1): Conv2d(\n",
      "                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "                )\n",
      "                (conv2): Conv2d(\n",
      "                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "                )\n",
      "                (conv3): Conv2d(\n",
      "                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "                )\n",
      "              )\n",
      "              (4): BottleneckBlock(\n",
      "                (conv1): Conv2d(\n",
      "                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "                )\n",
      "                (conv2): Conv2d(\n",
      "                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "                )\n",
      "                (conv3): Conv2d(\n",
      "                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "                )\n",
      "              )\n",
      "              (5): BottleneckBlock(\n",
      "                (conv1): Conv2d(\n",
      "                  1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "                )\n",
      "                (conv2): Conv2d(\n",
      "                  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "                  (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "                )\n",
      "                (conv3): Conv2d(\n",
      "                  256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "                  (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (res5): Sequential(\n",
      "              (0): BottleneckBlock(\n",
      "                (shortcut): Conv2d(\n",
      "                  1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "                )\n",
      "                (conv1): Conv2d(\n",
      "                  1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "                )\n",
      "                (conv2): Conv2d(\n",
      "                  512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
      "                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "                )\n",
      "                (conv3): Conv2d(\n",
      "                  512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "                )\n",
      "              )\n",
      "              (1): BottleneckBlock(\n",
      "                (conv1): Conv2d(\n",
      "                  2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "                )\n",
      "                (conv2): Conv2d(\n",
      "                  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "                )\n",
      "                (conv3): Conv2d(\n",
      "                  512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "                )\n",
      "              )\n",
      "              (2): BottleneckBlock(\n",
      "                (conv1): Conv2d(\n",
      "                  2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "                )\n",
      "                (conv2): Conv2d(\n",
      "                  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "                  (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "                )\n",
      "                (conv3): Conv2d(\n",
      "                  512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "                  (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): PositionEmbeddingSine()\n",
      "      )\n",
      "    )\n",
      "    (bbox_attention): MHAttentionMap(\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (q_linear): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (k_linear): Linear(in_features=256, out_features=256, bias=True)\n",
      "    )\n",
      "    (mask_head): MaskHeadSmallConv(\n",
      "      (lay1): Conv2d(264, 264, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (gn1): GroupNorm(8, 264, eps=1e-05, affine=True)\n",
      "      (lay2): Conv2d(264, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (gn2): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "      (lay3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (gn3): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "      (lay4): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (gn4): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "      (lay5): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (gn5): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
      "      (out_lay): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (adapter1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (adapter2): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (adapter3): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (criterion): SetCriterion(\n",
      "    (matcher): HungarianMatcher()\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/04 04:49:47 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[07/04 04:49:47 d2.data.datasets.coco]: \u001b[0mLoaded 33 images in COCO format from train.json\n",
      "\u001b[32m[07/04 04:49:47 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|    tail    | 90           |    mid     | 130          |    head    | 164          |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 384          |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[07/04 04:49:47 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/04 04:49:47 d2.data.common]: \u001b[0mSerializing 33 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/04 04:49:47 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mcriterion.empty_weight\u001b[0m\n",
      "\u001b[34mdetr.bbox_attention.k_linear.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.bbox_attention.q_linear.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res2.0.conv1.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res2.0.conv1.weight\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res2.0.conv2.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res2.0.conv2.weight\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res2.0.conv3.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res2.0.conv3.weight\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res2.0.shortcut.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res2.0.shortcut.weight\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res2.1.conv1.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res2.1.conv1.weight\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res2.1.conv2.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res2.1.conv2.weight\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res2.1.conv3.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res2.1.conv3.weight\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res2.2.conv1.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res2.2.conv1.weight\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res2.2.conv2.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res2.2.conv2.weight\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res2.2.conv3.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res2.2.conv3.weight\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res3.0.conv1.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res3.0.conv1.weight\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res3.0.conv2.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res3.0.conv2.weight\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res3.0.conv3.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res3.0.conv3.weight\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res3.0.shortcut.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res3.0.shortcut.weight\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res3.1.conv1.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res3.1.conv1.weight\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res3.1.conv2.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res3.1.conv2.weight\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res3.1.conv3.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res3.1.conv3.weight\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res3.2.conv1.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res3.2.conv1.weight\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res3.2.conv2.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res3.2.conv2.weight\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res3.2.conv3.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res3.2.conv3.weight\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res3.3.conv1.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res3.3.conv1.weight\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res3.3.conv2.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res3.3.conv2.weight\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res3.3.conv3.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res3.3.conv3.weight\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res4.0.conv1.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res4.0.conv1.weight\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res4.0.conv2.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res4.0.conv2.weight\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res4.0.conv3.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res4.0.conv3.weight\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res4.0.shortcut.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res4.0.shortcut.weight\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res4.1.conv1.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res4.1.conv1.weight\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res4.1.conv2.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res4.1.conv2.weight\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res4.1.conv3.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res4.1.conv3.weight\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res4.2.conv1.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res4.2.conv1.weight\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res4.2.conv2.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res4.2.conv2.weight\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res4.2.conv3.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res4.2.conv3.weight\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res4.3.conv1.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res4.3.conv1.weight\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res4.3.conv2.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res4.3.conv2.weight\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res4.3.conv3.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res4.3.conv3.weight\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res4.4.conv1.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res4.4.conv1.weight\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res4.4.conv2.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res4.4.conv2.weight\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res4.4.conv3.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res4.4.conv3.weight\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res4.5.conv1.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res4.5.conv1.weight\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res4.5.conv2.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res4.5.conv2.weight\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res4.5.conv3.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res4.5.conv3.weight\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res5.0.conv1.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res5.0.conv1.weight\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res5.0.conv2.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res5.0.conv2.weight\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res5.0.conv3.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res5.0.conv3.weight\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res5.0.shortcut.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res5.0.shortcut.weight\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res5.1.conv1.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res5.1.conv1.weight\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res5.1.conv2.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res5.1.conv2.weight\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res5.1.conv3.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res5.1.conv3.weight\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res5.2.conv1.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res5.2.conv1.weight\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res5.2.conv2.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res5.2.conv2.weight\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res5.2.conv3.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.res5.2.conv3.weight\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.stem.conv1.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.backbone.0.backbone.stem.conv1.weight\u001b[0m\n",
      "\u001b[34mdetr.detr.bbox_embed.layers.0.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.bbox_embed.layers.1.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.bbox_embed.layers.2.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.class_embed.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.input_proj.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.query_embed.weight\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.decoder.layers.0.linear1.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.decoder.layers.0.linear2.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.decoder.layers.0.multihead_attn.out_proj.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.decoder.layers.0.norm1.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.decoder.layers.0.norm2.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.decoder.layers.0.norm3.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.decoder.layers.0.self_attn.out_proj.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.decoder.layers.0.self_attn.{in_proj_bias, in_proj_weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.decoder.layers.1.linear1.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.decoder.layers.1.linear2.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.decoder.layers.1.multihead_attn.out_proj.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.decoder.layers.1.multihead_attn.{in_proj_bias, in_proj_weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.decoder.layers.1.norm1.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.decoder.layers.1.norm2.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.decoder.layers.1.norm3.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.decoder.layers.1.self_attn.out_proj.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.decoder.layers.1.self_attn.{in_proj_bias, in_proj_weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.decoder.layers.2.linear1.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.decoder.layers.2.linear2.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.decoder.layers.2.multihead_attn.out_proj.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.decoder.layers.2.multihead_attn.{in_proj_bias, in_proj_weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.decoder.layers.2.norm1.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.decoder.layers.2.norm2.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.decoder.layers.2.norm3.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.decoder.layers.2.self_attn.out_proj.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.decoder.layers.2.self_attn.{in_proj_bias, in_proj_weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.decoder.layers.3.linear1.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.decoder.layers.3.linear2.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.decoder.layers.3.multihead_attn.out_proj.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.decoder.layers.3.multihead_attn.{in_proj_bias, in_proj_weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.decoder.layers.3.norm1.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.decoder.layers.3.norm2.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.decoder.layers.3.norm3.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.decoder.layers.3.self_attn.out_proj.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.decoder.layers.3.self_attn.{in_proj_bias, in_proj_weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.decoder.layers.4.linear1.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.decoder.layers.4.linear2.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.decoder.layers.4.multihead_attn.out_proj.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.decoder.layers.4.multihead_attn.{in_proj_bias, in_proj_weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.decoder.layers.4.norm1.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.decoder.layers.4.norm2.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.decoder.layers.4.norm3.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.decoder.layers.4.self_attn.out_proj.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.decoder.layers.4.self_attn.{in_proj_bias, in_proj_weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.decoder.layers.5.linear1.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.decoder.layers.5.linear2.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.decoder.layers.5.multihead_attn.out_proj.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.decoder.layers.5.multihead_attn.{in_proj_bias, in_proj_weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.decoder.layers.5.norm1.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.decoder.layers.5.norm2.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.decoder.layers.5.norm3.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.decoder.layers.5.self_attn.out_proj.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.decoder.layers.5.self_attn.{in_proj_bias, in_proj_weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.decoder.norm.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.encoder.layers.0.linear1.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.encoder.layers.0.linear2.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.encoder.layers.0.norm1.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.encoder.layers.0.norm2.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.encoder.layers.0.self_attn.out_proj.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.encoder.layers.0.self_attn.{in_proj_bias, in_proj_weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.encoder.layers.1.linear1.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.encoder.layers.1.linear2.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.encoder.layers.1.norm1.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.encoder.layers.1.norm2.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.encoder.layers.1.self_attn.out_proj.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.encoder.layers.1.self_attn.{in_proj_bias, in_proj_weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.encoder.layers.2.linear1.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.encoder.layers.2.linear2.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.encoder.layers.2.norm1.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.encoder.layers.2.norm2.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.encoder.layers.2.self_attn.out_proj.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.encoder.layers.2.self_attn.{in_proj_bias, in_proj_weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.encoder.layers.3.linear1.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.encoder.layers.3.linear2.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.encoder.layers.3.norm1.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.encoder.layers.3.norm2.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.encoder.layers.3.self_attn.out_proj.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.encoder.layers.3.self_attn.{in_proj_bias, in_proj_weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.encoder.layers.4.linear1.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.encoder.layers.4.linear2.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.encoder.layers.4.norm1.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.encoder.layers.4.norm2.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.encoder.layers.4.self_attn.out_proj.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.encoder.layers.4.self_attn.{in_proj_bias, in_proj_weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.encoder.layers.5.linear1.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.encoder.layers.5.linear2.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.encoder.layers.5.norm1.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.encoder.layers.5.norm2.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.encoder.layers.5.self_attn.out_proj.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.detr.transformer.encoder.layers.5.self_attn.{in_proj_bias, in_proj_weight}\u001b[0m\n",
      "\u001b[34mdetr.mask_head.adapter1.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.mask_head.adapter2.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.mask_head.adapter3.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.mask_head.gn1.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.mask_head.gn2.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.mask_head.gn3.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.mask_head.gn4.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.mask_head.gn5.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.mask_head.lay1.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.mask_head.lay2.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.mask_head.lay3.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.mask_head.lay4.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.mask_head.lay5.{bias, weight}\u001b[0m\n",
      "\u001b[34mdetr.mask_head.out_lay.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mtransformer.encoder.layers.0.self_attn.{in_proj_bias, in_proj_weight}\u001b[0m\n",
      "  \u001b[35mtransformer.encoder.layers.0.self_attn.out_proj.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.encoder.layers.0.linear1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.encoder.layers.0.linear2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.encoder.layers.0.norm1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.encoder.layers.0.norm2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.encoder.layers.1.self_attn.{in_proj_bias, in_proj_weight}\u001b[0m\n",
      "  \u001b[35mtransformer.encoder.layers.1.self_attn.out_proj.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.encoder.layers.1.linear1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.encoder.layers.1.linear2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.encoder.layers.1.norm1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.encoder.layers.1.norm2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.encoder.layers.2.self_attn.{in_proj_bias, in_proj_weight}\u001b[0m\n",
      "  \u001b[35mtransformer.encoder.layers.2.self_attn.out_proj.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.encoder.layers.2.linear1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.encoder.layers.2.linear2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.encoder.layers.2.norm1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.encoder.layers.2.norm2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.encoder.layers.3.self_attn.{in_proj_bias, in_proj_weight}\u001b[0m\n",
      "  \u001b[35mtransformer.encoder.layers.3.self_attn.out_proj.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.encoder.layers.3.linear1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.encoder.layers.3.linear2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.encoder.layers.3.norm1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.encoder.layers.3.norm2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.encoder.layers.4.self_attn.{in_proj_bias, in_proj_weight}\u001b[0m\n",
      "  \u001b[35mtransformer.encoder.layers.4.self_attn.out_proj.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.encoder.layers.4.linear1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.encoder.layers.4.linear2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.encoder.layers.4.norm1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.encoder.layers.4.norm2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.encoder.layers.5.self_attn.{in_proj_bias, in_proj_weight}\u001b[0m\n",
      "  \u001b[35mtransformer.encoder.layers.5.self_attn.out_proj.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.encoder.layers.5.linear1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.encoder.layers.5.linear2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.encoder.layers.5.norm1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.encoder.layers.5.norm2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.decoder.layers.0.self_attn.{in_proj_bias, in_proj_weight}\u001b[0m\n",
      "  \u001b[35mtransformer.decoder.layers.0.self_attn.out_proj.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}\u001b[0m\n",
      "  \u001b[35mtransformer.decoder.layers.0.multihead_attn.out_proj.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.decoder.layers.0.linear1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.decoder.layers.0.linear2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.decoder.layers.0.norm1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.decoder.layers.0.norm2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.decoder.layers.0.norm3.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.decoder.layers.1.self_attn.{in_proj_bias, in_proj_weight}\u001b[0m\n",
      "  \u001b[35mtransformer.decoder.layers.1.self_attn.out_proj.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.decoder.layers.1.multihead_attn.{in_proj_bias, in_proj_weight}\u001b[0m\n",
      "  \u001b[35mtransformer.decoder.layers.1.multihead_attn.out_proj.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.decoder.layers.1.linear1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.decoder.layers.1.linear2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.decoder.layers.1.norm1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.decoder.layers.1.norm2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.decoder.layers.1.norm3.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.decoder.layers.2.self_attn.{in_proj_bias, in_proj_weight}\u001b[0m\n",
      "  \u001b[35mtransformer.decoder.layers.2.self_attn.out_proj.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.decoder.layers.2.multihead_attn.{in_proj_bias, in_proj_weight}\u001b[0m\n",
      "  \u001b[35mtransformer.decoder.layers.2.multihead_attn.out_proj.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.decoder.layers.2.linear1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.decoder.layers.2.linear2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.decoder.layers.2.norm1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.decoder.layers.2.norm2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.decoder.layers.2.norm3.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.decoder.layers.3.self_attn.{in_proj_bias, in_proj_weight}\u001b[0m\n",
      "  \u001b[35mtransformer.decoder.layers.3.self_attn.out_proj.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.decoder.layers.3.multihead_attn.{in_proj_bias, in_proj_weight}\u001b[0m\n",
      "  \u001b[35mtransformer.decoder.layers.3.multihead_attn.out_proj.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.decoder.layers.3.linear1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.decoder.layers.3.linear2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.decoder.layers.3.norm1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.decoder.layers.3.norm2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.decoder.layers.3.norm3.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.decoder.layers.4.self_attn.{in_proj_bias, in_proj_weight}\u001b[0m\n",
      "  \u001b[35mtransformer.decoder.layers.4.self_attn.out_proj.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.decoder.layers.4.multihead_attn.{in_proj_bias, in_proj_weight}\u001b[0m\n",
      "  \u001b[35mtransformer.decoder.layers.4.multihead_attn.out_proj.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.decoder.layers.4.linear1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.decoder.layers.4.linear2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.decoder.layers.4.norm1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.decoder.layers.4.norm2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.decoder.layers.4.norm3.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.decoder.layers.5.self_attn.{in_proj_bias, in_proj_weight}\u001b[0m\n",
      "  \u001b[35mtransformer.decoder.layers.5.self_attn.out_proj.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.decoder.layers.5.multihead_attn.{in_proj_bias, in_proj_weight}\u001b[0m\n",
      "  \u001b[35mtransformer.decoder.layers.5.multihead_attn.out_proj.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.decoder.layers.5.linear1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.decoder.layers.5.linear2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.decoder.layers.5.norm1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.decoder.layers.5.norm2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.decoder.layers.5.norm3.{bias, weight}\u001b[0m\n",
      "  \u001b[35mtransformer.decoder.norm.{bias, weight}\u001b[0m\n",
      "  \u001b[35mclass_embed.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbbox_embed.layers.0.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbbox_embed.layers.1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbbox_embed.layers.2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mquery_embed.weight\u001b[0m\n",
      "  \u001b[35minput_proj.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.bn1.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer1.0.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer1.0.bn1.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer1.0.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer1.0.bn2.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer1.0.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer1.0.bn3.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer1.0.downsample.0.weight\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer1.0.downsample.1.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer1.1.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer1.1.bn1.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer1.1.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer1.1.bn2.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer1.1.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer1.1.bn3.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer1.2.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer1.2.bn1.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer1.2.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer1.2.bn2.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer1.2.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer1.2.bn3.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer2.0.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer2.0.bn1.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer2.0.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer2.0.bn2.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer2.0.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer2.0.bn3.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer2.0.downsample.0.weight\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer2.0.downsample.1.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer2.1.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer2.1.bn1.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer2.1.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer2.1.bn2.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer2.1.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer2.1.bn3.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer2.2.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer2.2.bn1.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer2.2.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer2.2.bn2.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer2.2.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer2.2.bn3.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer2.3.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer2.3.bn1.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer2.3.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer2.3.bn2.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer2.3.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer2.3.bn3.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer3.0.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer3.0.bn1.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer3.0.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer3.0.bn2.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer3.0.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer3.0.bn3.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer3.0.downsample.0.weight\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer3.0.downsample.1.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer3.1.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer3.1.bn1.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer3.1.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer3.1.bn2.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer3.1.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer3.1.bn3.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer3.2.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer3.2.bn1.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer3.2.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer3.2.bn2.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer3.2.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer3.2.bn3.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer3.3.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer3.3.bn1.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer3.3.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer3.3.bn2.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer3.3.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer3.3.bn3.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer3.4.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer3.4.bn1.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer3.4.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer3.4.bn2.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer3.4.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer3.4.bn3.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer3.5.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer3.5.bn1.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer3.5.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer3.5.bn2.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer3.5.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer3.5.bn3.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer4.0.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer4.0.bn1.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer4.0.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer4.0.bn2.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer4.0.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer4.0.bn3.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer4.0.downsample.0.weight\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer4.0.downsample.1.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer4.1.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer4.1.bn1.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer4.1.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer4.1.bn2.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer4.1.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer4.1.bn3.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer4.2.conv1.weight\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer4.2.bn1.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer4.2.conv2.weight\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer4.2.bn2.{bias, running_mean, running_var, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer4.2.conv3.weight\u001b[0m\n",
      "  \u001b[35mbackbone.0.body.layer4.2.bn3.{bias, running_mean, running_var, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/04 04:49:48 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/step/.local/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "/home/step/.local/lib/python3.9/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4m\u001b[5m\u001b[31mERROR\u001b[0m \u001b[32m[07/04 04:49:49 d2.engine.train_loop]: \u001b[0mException during training:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/step/Code/detectron2/detectron2/engine/train_loop.py\", line 149, in train\n",
      "    self.run_step()\n",
      "  File \"/home/step/Code/detectron2/detectron2/engine/defaults.py\", line 497, in run_step\n",
      "    self._trainer.run_step()\n",
      "  File \"/home/step/Code/detectron2/detectron2/engine/train_loop.py\", line 273, in run_step\n",
      "    loss_dict = self.model(data)\n",
      "  File \"/home/step/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/step/Personal/UCH/2021-sem1/VisionComp/t4/detr/d2/detr/detr.py\", line 177, in forward\n",
      "    output = self.detr(images)\n",
      "  File \"/home/step/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/step/Personal/UCH/2021-sem1/VisionComp/t4/detr/models/segmentation.py\", line 58, in forward\n",
      "    seg_masks = self.mask_head(src_proj, bbox_mask, [features[2].tensors, features[1].tensors, features[0].tensors])\n",
      "  File \"/home/step/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/step/Personal/UCH/2021-sem1/VisionComp/t4/detr/models/segmentation.py\", line 131, in forward\n",
      "    x = cur_fpn + F.interpolate(x, size=cur_fpn.shape[-2:], mode=\"nearest\")\n",
      "  File \"/home/step/.local/lib/python3.9/site-packages/torch/nn/functional.py\", line 3690, in interpolate\n",
      "    return torch._C._nn.upsample_nearest2d(input, output_size, scale_factors)\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 608.00 MiB (GPU 0; 7.79 GiB total capacity; 3.70 GiB already allocated; 651.44 MiB free; 4.45 GiB reserved in total by PyTorch)\n",
      "\u001b[32m[07/04 04:49:49 d2.engine.hooks]: \u001b[0mOverall training speed: 3 iterations in 0:00:00 (0.2695 s / it)\n",
      "\u001b[32m[07/04 04:49:49 d2.engine.hooks]: \u001b[0mTotal training time: 0:00:00 (0:00:00 on hooks)\n",
      "\u001b[32m[07/04 04:49:49 d2.utils.events]: \u001b[0m eta: 6:30:48  iter: 5  total_loss: 601.5  loss_ce: 3.627  loss_bbox: 5.978  loss_giou: 2.242  loss_mask: 0.05298  loss_dice: 0.9988  loss_ce_0: 3.61  loss_bbox_0: 5.995  loss_giou_0: 2.262  loss_ce_1: 3.86  loss_bbox_1: 5.98  loss_giou_1: 2.246  loss_ce_2: 3.464  loss_bbox_2: 6.034  loss_giou_2: 2.232  loss_ce_3: 3.257  loss_bbox_3: 6.024  loss_giou_3: 2.218  loss_ce_4: 3.182  loss_bbox_4: 6.051  loss_giou_4: 2.236  time: 0.2380  data_time: 0.0764  lr: 0.0001  max_mem: 4053M\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 608.00 MiB (GPU 0; 7.79 GiB total capacity; 3.70 GiB already allocated; 651.44 MiB free; 4.45 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1817901/2957596158.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume_or_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Code/detectron2/detectron2/engine/defaults.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    485\u001b[0m             \u001b[0mOrderedDict\u001b[0m \u001b[0mof\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mevaluation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0menabled\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mOtherwise\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m         \"\"\"\n\u001b[0;32m--> 487\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXPECTED_RESULTS\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcomm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_main_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m             assert hasattr(\n",
      "\u001b[0;32m~/Code/detectron2/detectron2/engine/train_loop.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, start_iter, max_iter)\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                 \u001b[0;31m# self.iter == max_iter can be used by `after_train` to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/detectron2/detectron2/engine/defaults.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    495\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/detectron2/detectron2/engine/train_loop.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mIf\u001b[0m \u001b[0myou\u001b[0m \u001b[0mwant\u001b[0m \u001b[0mto\u001b[0m \u001b[0mdo\u001b[0m \u001b[0msomething\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myou\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mwrap\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \"\"\"\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0mloss_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Personal/UCH/2021-sem1/VisionComp/t4/detr/d2/detr/detr.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batched_inputs)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \"\"\"\n\u001b[1;32m    176\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Personal/UCH/2021-sem1/VisionComp/t4/detr/models/segmentation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, samples)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mbbox_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbbox_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mseg_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_proj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0moutputs_seg_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseg_masks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_queries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseg_masks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseg_masks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Personal/UCH/2021-sem1/VisionComp/t4/detr/models/segmentation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, bbox_mask, fpns)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcur_fpn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mcur_fpn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_fpn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mcur_fpn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcur_fpn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_fpn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"nearest\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlay5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgn5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36minterpolate\u001b[0;34m(input, size, scale_factor, mode, align_corners, recompute_scale_factor)\u001b[0m\n\u001b[1;32m   3688\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsample_nearest1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_factors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3689\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"nearest\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3690\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsample_nearest2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_factors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3691\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"nearest\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3692\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsample_nearest3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_factors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 608.00 MiB (GPU 0; 7.79 GiB total capacity; 3.70 GiB already allocated; 651.44 MiB free; 4.45 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(1, os.path.join(sys.path[0], 'detr'))\n",
    "\n",
    "from detr.d2.train_net import add_detr_config, Trainer\n",
    "\n",
    "\n",
    "cfg = get_cfg()\n",
    "add_detr_config(cfg)\n",
    "\n",
    "cfg.merge_from_file('detrd2/configs/detr_segm_256_6_6_torchvision.yaml')\n",
    "cfg.DATASETS.TRAIN = (\"sperm-train\",)\n",
    "cfg.DATASETS.TEST = (\"sperm-test\",)\n",
    "cfg.TEST.EVAL_PERIOD = 250\n",
    "cfg.DATALOADER.NUM_WORKERS = 9\n",
    "cfg.MODEL.WEIGHTS = 'https://dl.fbaipublicfiles.com/detr/detr-r50-dc5-f0fb7ef5.pth'\n",
    "cfg.SOLVER.IMS_PER_BATCH = 1\n",
    "# cfg.SOLVER.BASE_LR = 0.00020  # pick a good LR\n",
    "# cfg.SOLVER.MAX_ITER = 2500    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
    "\n",
    "# cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
    "\n",
    "# faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 32 \n",
    "# # see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3  \n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = Trainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a3eeb7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-04T08:49:49.996999Z",
     "start_time": "2021-07-04T08:49:49.996991Z"
    }
   },
   "outputs": [],
   "source": [
    "!ls /home/step/Personal/UCH/2021-sem1/VisionComp/t4/data/SpermSegGS/images/train/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077f839c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:detectron]",
   "language": "python",
   "name": "conda-env-detectron-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
